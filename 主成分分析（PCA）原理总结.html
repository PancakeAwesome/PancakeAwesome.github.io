<!DOCTYPE html><html style="display:none" lang="zh"><head><meta charset="utf-8"><script>window.materialVersion="1.5.0",window.oldVersion=["codestartv1","1.3.4","1.4.0","1.4.0b1"]</script><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://busuanzi.ibruce.info"><link rel="dns-prefetch" href="https://changyan.sohu.com"><title> 主成分分析（PCA）和白化（whitening）原理总结 | Edward&#39;s Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0097A7"><meta name="author" content="Edward Guan"><meta name="description" itemprop="description" content="主成分分析（PCA）降维"><meta name="keywords" content="前端,node,react,js,java,自学编程,学习分享,UESTC,机器学习"><script>window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}},lsloader.removeLS=function(e){try{localStorage.removeItem(e)}catch(e){}},lsloader.setLS=function(e,t){try{localStorage.setItem(e,t)}catch(e){}},lsloader.getLS=function(e){var t="";try{t=localStorage.getItem(e)}catch(e){t=""}return t},versionString="/*"+(window.materialVersion||"unknownVersion")+"*/",lsloader.clean=function(){try{for(var e=[],t=0;t<localStorage.length;t++)e.push(localStorage.key(t));e.forEach(function(e){var t=lsloader.getLS(e);window.oldVersion&&window.oldVersion.reduce(function(e,n){return e||-1!==t.indexOf("/*"+n+"*/")},!1)&&lsloader.removeLS(e)})}catch(e){}},lsloader.clean(),lsloader.load=function(e,t,n,s){"boolean"==typeof n&&(s=n,n=void 0),s=s||!1,n=n||function(){};var a;if((a=this.getLS(e))&&-1===a.indexOf(versionString))return this.removeLS(e),void this.requestResource(e,t,n,s);if(a){if(a.split(versionString)[0]!=t)return console.log("reload:"+t),this.removeLS(e),void this.requestResource(e,t,n,s);a=a.split(versionString)[1],s?(this.jsRunSequence.push({name:e,code:a}),this.runjs(t,e,a)):(document.getElementById(e).appendChild(document.createTextNode(a)),n())}else this.requestResource(e,t,n,s)},lsloader.requestResource=function(e,t,n,s){var a=this;s?this.iojs(t,e,function(e,t,n){a.setLS(t,e+versionString+n),a.runjs(e,t,n)}):this.iocss(t,e,function(n){document.getElementById(e).appendChild(document.createTextNode(n)),a.setLS(e,t+versionString+n)},n)},lsloader.iojs=function(e,t,n){var s=this;s.jsRunSequence.push({name:t,code:""});try{var a=new XMLHttpRequest;a.open("get",e,!0),a.onreadystatechange=function(){if(4==a.readyState){if((a.status>=200&&a.status<300||304==a.status)&&""!=a.response)return void n(e,t,a.response);s.jsfallback(e,t)}},a.send(null)}catch(n){s.jsfallback(e,t)}},lsloader.iocss=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.iofonts=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.runjs=function(e,t,n){if(t&&n)for(var s in this.jsRunSequence)this.jsRunSequence[s].name==t&&(this.jsRunSequence[s].code=n);if(this.jsRunSequence[0]&&this.jsRunSequence[0].code&&"failed"!=this.jsRunSequence[0].status)(o=document.createElement("script")).appendChild(document.createTextNode(this.jsRunSequence[0].code)),o.type="text/javascript",document.getElementsByTagName("head")[0].appendChild(o),this.jsRunSequence.shift(),this.jsRunSequence.length>0&&this.runjs();else if(this.jsRunSequence[0]&&"failed"==this.jsRunSequence[0].status){var a=this,o=document.createElement("script");o.src=this.jsRunSequence[0].path,o.type="text/javascript",this.jsRunSequence[0].status="loading",o.onload=function(){a.jsRunSequence.shift(),a.jsRunSequence.length>0&&a.runjs()},document.body.appendChild(o)}},lsloader.tagLoad=function(e,t){this.jsRunSequence.push({name:t,code:"",path:e,status:"failed"}),this.runjs()},lsloader.jsfallback=function(e,t){if(!this.jsnamemap[t]){this.jsnamemap[t]=t;for(var n in this.jsRunSequence)this.jsRunSequence[n].name==t&&(this.jsRunSequence[n].code="",this.jsRunSequence[n].status="failed",this.jsRunSequence[n].path=e);this.runjs()}},lsloader.cssfallback=function(e,t,n){if(!this.cssnamemap[t]){this.cssnamemap[t]=1;var s=document.createElement("link");s.type="text/css",s.href=e,s.rel="stylesheet",s.onload=s.onerror=n;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(s,a)}},lsloader.runInlineScript=function(e,t){var n=document.getElementById(t).innerText;this.jsRunSequence.push({name:e,code:n}),this.runjs()},lsloader.loadCombo=function(e){var t="",n={};for(var s in e){var a=this.getLS(e[s].name);if(a)var o=a.split(versionString)[0],i=a.split(versionString)[1];else o="";o==e[s].path?this.jsRunSequence.push({name:e[s].name,code:i,path:e[s].path}):(this.jsRunSequence.push({name:e[s].name,code:null,path:e[s].path,status:"comboloading"}),n[e[s].name]=!0,t+=(""==t?"":";")+e[s].path)}var u=this;if(t){var r=new XMLHttpRequest;r.open("get",combo+t,!0),r.onreadystatechange=function(){if(4==r.readyState)if(r.status>=200&&r.status<300||304==r.status){if(""!=r.response)return void u.runCombo(r.response,n)}else{for(var e in u.jsRunSequence)n[u.jsRunSequence[e].name]&&(u.jsRunSequence[e].status="failed");u.runjs()}},r.send(null)}this.runjs()},lsloader.runCombo=function(e,t){(e=e.split("/*combojs*/")).shift();for(var n in this.jsRunSequence)t[this.jsRunSequence[n].name]&&e[0]&&(this.jsRunSequence[n].status="comboJS",this.jsRunSequence[n].code=e[0],this.setLS(this.jsRunSequence[n].name,this.jsRunSequence[n].path+versionString+e[0]),e.shift());this.runjs()}</script><script>function Queue(){this.dataStore=[],this.offer=function(e){this.debug&&console.log("Offered a Queued Function."),"function"==typeof e?this.dataStore.push(e):console.log("You must offer a function.")},this.poll=function(){return this.debug&&console.log("Polled a Queued Function."),this.dataStore.shift()},this.execNext=function(){var e=this.poll();void 0!==e&&(this.debug&&console.log("Run a Queued Function."),e())},this.debug=!1,this.startDebug=function(){this.debug=!0}}var queue=new Queue</script><link rel="icon shortcut" type="image/ico" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="icon" sizes="192x192" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="apple-touch-icon" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="apple-mobile-web-app-title" content="Title"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="480"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="apple-mobile-web-app-title" content="Edward&#39;s Blog"> <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie-blocker.css"><script src="/js/ie-blocker.zhCN.js"></script><![endif]--><style id="material_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="style_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_theme"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_theme","/css/prettify/github-v2.min.css?AfzKxt++K+/lhZBlSjnxwg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style>body,html{font-family:Roboto,"Helvetica Neue",Helvetica,"PingFang SC","Hiragino Sans GB","Microsoft YaHei","微软雅黑",Arial,sans-serif;overflow-x:hidden!important}code{font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace}a{color:#00838f}#scheme-Paradox .hot_tags-count,#scheme-Paradox .sidebar-colored .sidebar-badge,#scheme-Paradox .sidebar-colored .sidebar-header,#scheme-Paradox .sidebar_archives-count,#search-form-label:after,#search-label,.mdl-card__media{background-color:#0097a7!important}#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus,#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover{color:#0097a7!important}#ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a,#post_entry-right-info,.sidebar-colored .sidebar-nav li:hover>a,.sidebar-colored .sidebar-nav li:hover>a i,.sidebar-colored .sidebar-nav li>a:focus i,.sidebar-colored .sidebar-nav li>a:hover,.sidebar-colored .sidebar-nav li>a:hover i,.sidebar-colored .sidebar-nav>.open>a,.sidebar-colored .sidebar-nav>.open>a:focus,.sidebar-colored .sidebar-nav>.open>a:hover{color:#0097a7!important}.toTop{background:#757575!important}.material-layout .material-index>.material-nav,.material-layout .material-post>.material-nav,.material-nav a{color:#757575}#scheme-Paradox .MD-burger-layer{background-color:#757575}#scheme-Paradox #post-toc-trigger-btn{color:#757575}.post-toc a:hover{color:#00838f;text-decoration:underline}</style><style>body{background-color:#f5f5f5}#scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{background-color:#fff}</style><style>.fade{transition:all .8s linear;-webkit-transform:translate3d(0,0,0);-moz-transform:translate3d(0,0,0);-ms-transform:translate3d(0,0,0);-o-transform:translate3d(0,0,0);transform:translate3d(0,0,0);opacity:1}.fade.out{opacity:0}</style><link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet"><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"><script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==",!0)</script><meta property="og:url" content="http://pancakeawesome.ink"><meta property="og:type" content="blog"><meta property="og:title" content="主成分分析（PCA）和白化（whitening）原理总结 | Edward&#39;s Blog"><meta property="og:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta property="og:description" content="主成分分析（PCA）降维"><meta property="og:article:tag" content="机器学习"><meta property="article:published_time" content="Mon Feb 26 2018 11:41:39 GMT+0800"><meta property="article:modified_time" content="Wed Mar 14 2018 15:22:56 GMT+0800"><meta name="twitter:title" content="主成分分析（PCA）和白化（whitening）原理总结 | Edward&#39;s Blog"><meta name="twitter:description" content="主成分分析（PCA）降维"><meta name="twitter:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="http://pancakeawesome.ink"><link rel="canonical" href="http://pancakeawesome.ink/主成分分析（PCA）原理总结.html"><script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://pancakeawesome.ink/主成分分析（PCA）原理总结.html",
    "headline": "主成分分析（PCA）和白化（whitening）原理总结",
    "datePublished": "Mon Feb 26 2018 11:41:39 GMT+0800",
    "dateModified": "Wed Mar 14 2018 15:22:56 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Edward Guan",
        "image": {
            "@type": "ImageObject",
            "url": "/img/rip.jpeg"
        },
        "description": "你说人生艳丽我没有异议，你说人生忧郁我不言语"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Edward&#39;s Blog",
        "logo": {
            "@type":"ImageObject",
            "url": "http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"
        }
    },
    "keywords": ",机器学习前端,node,react,js,java,自学编程,学习分享,UESTC",
    "description": "主成分分析（PCA）降维",
}
</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0c041dca6f79c4e40fb45d1283e327e7";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body id="scheme-Paradox" class="lazy"><div class="material-layout mdl-js-layout has-drawer is-upgraded"><main class="material-layout__content" id="main"><div id="top"></div> <button class="MD-burger-icon sidebar-toggle"><span class="MD-burger-layer"></span></button> <button id="post-toc-trigger-btn" class="mdl-button mdl-js-button mdl-button--icon"> <i class="material-icons">format_list_numbered</i></button><ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh;overflow-y:scroll"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#前言"><span class="post-toc-number">1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#主成分分析（PCA）原理总结"><span class="post-toc-number">2.</span> <span class="post-toc-text">主成分分析（PCA）原理总结</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1-PCA的思想"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">1. PCA的思想</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-PCA的推导-基于小于投影距离"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">2. PCA的推导:基于小于投影距离</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-PCA的推导-基于最大投影方差"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">3. PCA的推导:基于最大投影方差</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#4-PCA算法流程"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">4. PCA算法流程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#5-PCA实例"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">5. PCA实例</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#6-核主成分分析KPCA介绍"><span class="post-toc-number">2.6.</span> <span class="post-toc-text">6. 核主成分分析KPCA介绍</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#7-白化whitening"><span class="post-toc-number">2.7.</span> <span class="post-toc-text">7. 白化whitening</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#一、相关理论"><span class="post-toc-number">2.7.1.</span> <span class="post-toc-text">一、相关理论</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#二、算法概述"><span class="post-toc-number">2.7.2.</span> <span class="post-toc-text">二、算法概述</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#1、首先是PCA预处理"><span class="post-toc-number">2.7.2.1.</span> <span class="post-toc-text">1、首先是PCA预处理</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#2、PCA白化"><span class="post-toc-number">2.7.2.2.</span> <span class="post-toc-text">2、PCA白化</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#3、ZCA白化"><span class="post-toc-number">2.7.2.3.</span> <span class="post-toc-text">3、ZCA白化</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#8-PCA算法总结"><span class="post-toc-number">2.8.</span> <span class="post-toc-text">8. PCA算法总结</span></a></li></ol></li></ol></ul><div class="material-post_container"><div class="material-post mdl-grid"><div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col"><div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50"><script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 30 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script><p class="article-headline-p"> 主成分分析（PCA）和白化（whitening）原理总结</p></div><div class="mdl-color-text--grey-700 mdl-card__supporting-text meta"><div id="author-avatar"> <img src="/img/rip.jpeg" width="44px" height="44px" alt="Author Avatar"></div><div> <strong>Edward Guan</strong> <span>2月 26, 2018</span></div><div class="section-spacer"></div> <button id="article-functions-qrcode-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">devices other</i> <span class="visuallyhidden">devices other</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-qrcode-button"><li class="mdl-menu__item">在其它设备中阅读本文章</li> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPYAAAD2CAAAAADAeSUUAAAC2klEQVR42u3aUW7CMBAEUO5/6fYEgRlvEGC/fCEacJ4rdevZffwdeT2wsbGxsbGxsbGxv5L9iK/2/vzbrp4nuSdZBRsbG/sE9os//RcLX72+XPjiznyt0TNjY2NjH8DOy8xzfPLQz0tj/jxFacTGxsbGXqLmR4tka7CxsbGx38Ge3N+GR9jY2NjY81CpDfTf8dkPZGnY2NjYX89ea81+9vUH+tvY2NjYX8muRxiTBeLovyXdNnyJjY2NvRG7jfjzocznW5Y3A/Jye8MJDBsbG3sLdh7Z5NRJ6J9v34tfJDY2NvbB7LbJmn+2bRWsbRM2Njb2Cey6GJTRfBtXJaU02ThsbGzs09j5UGMe/ay1afMjUBFdYWNjY2/KToL7SfOgJc0DJmxsbOyT2clD5MeVPBiqxyjLQwg2Njb2Oey1sjGK7MvGw6gBjI2Njb0pOwnlE97k2+btgRsavdjY2Ng/zm4bBslBoo2u2nZCezTCxsbG3pWdNFCTcKfdoOQbJuUKGxsb+zT2/FjSRkLtprSlDhsbG/tMdvKv/13xU/5O29CtCxg2Njb2j7Mnwzp1q3VpNCf5zuR9bGxs7F3ZeTy0FvTk7du1MllsIjY2Nvam7Pww0I7mtIWtbSTUbWZsbGzsTdltk6AtJ/mG3ovHxsbGPoedHzySI8ddpDzAuqE9gI2Njf3j7PwRJ43hvOzNnwQbGxv7ZHZbitqmbBs5tcOadaMXGxsbewv2ZFwmj5kmpS6PkF6EX9jY2NibsttrMtzTbsfaoM9iVwQbGxv7Z9ntIGPLzqOidtCzjZ+wsbGx92a3MVNSqPJ2wnNAHnXVJzBsbGzs7djzohUtH8f6a2sVRxFsbGzsI9nRcEzcKs6jqEnxw8bGxsZei3jmB5g8cooaG9jY2NgHsOdDOfPgqRjBaVvC2NjY2Fuz20bvBLNWnPKfvrG/jY2Njf2V7HMubGxsbGxsbGxs7K+5/gHuE3vu4gY07AAAAABJRU5ErkJggg=="></ul> <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">bookmark</i> <span class="visuallyhidden">bookmark</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button"><li class="mdl-menu__item"> <a class="post_tag-link" href="/tags/机器学习/">机器学习</a></li></ul> <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">share</i> <span class="visuallyhidden">share</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button"><a class="post_share-link" href="#"><li class="mdl-menu__item"><span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span> &nbsp;浏览量</span></li></a><a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=主成分分析（PCA）和白化（whitening）原理总结&url=http://pancakeawesome.ink/主成分分析（PCA）原理总结.html&pic=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&searchPic=false&style=simple" target="_blank"><li class="mdl-menu__item"> 分享到微博</li></a><a class="post_share-link" href="https://twitter.com/intent/tweet?text=主成分分析（PCA）和白化（whitening）原理总结&url=http://pancakeawesome.ink/主成分分析（PCA）原理总结.html&via=Edward Guan" target="_blank"><li class="mdl-menu__item"> 分享到 Twitter</li></a><a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://pancakeawesome.ink/主成分分析（PCA）原理总结.html" target="_blank"><li class="mdl-menu__item"> 分享到 Facebook</li></a><a class="post_share-link" href="https://plus.google.com/share?url=http://pancakeawesome.ink/主成分分析（PCA）原理总结.html" target="_blank"><li class="mdl-menu__item"> 分享到 Google+</li></a><a class="post_share-link" href="https://www.linkedin.com/shareArticle?mini=true&url=http://pancakeawesome.ink/主成分分析（PCA）原理总结.html&title=主成分分析（PCA）和白化（whitening）原理总结" target="_blank"><li class="mdl-menu__item"> 分享到 LinkedIn</li></a><a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Edward&#39;s Blog&title=主成分分析（PCA）和白化（whitening）原理总结&summary=技术分享,学习笔记&pics=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&url=http://pancakeawesome.ink/主成分分析（PCA）原理总结.html" target="_blank"><li class="mdl-menu__item"> 分享到 QQ</li></a></ul></div><div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>主成分分析（Principal components analysis，以下简称PCA）是最重要的降维方法之一。在数据压缩消除冗余和数据噪音消除等领域都有广泛的应用。一般我们提到降维最容易想到的算法就是PCA，下面我们就对PCA的原理做一个总结。</p><h2 id="主成分分析（PCA）原理总结"><a href="#主成分分析（PCA）原理总结" class="headerlink" title="主成分分析（PCA）原理总结"></a>主成分分析（PCA）原理总结</h2><h3 id="1-PCA的思想"><a href="#1-PCA的思想" class="headerlink" title="1. PCA的思想"></a>1. PCA的思想</h3><p>PCA顾名思义，就是找出数据里最主要的方面，用数据里最主要的方面来代替原始数据。具体的，假如我们的数据集是n维的，共有m个数据$(x^{(1)},x^{(2)},…,x^{(m)})$。我们希望将这m个数据的维度从n维降到n’维，希望这m个n’维的数据集尽可能的代表原始数据集。我们知道数据从n维降到n’维肯定会有损失，但是我们希望损失尽可能的小。那么如何让这n’维的数据尽可能表示原来的数据呢？</p><p>我们先看看最简单的情况，也就是n=2，n’=1,也就是将数据从二维降维到一维。数据如下图。我们希望找到某一个维度方向，它可以代表这两个维度的数据。图中列了两个向量方向，$u_1和u_2$，那么哪个向量可以更好的代表原始数据集呢？从直观上也可以看出，$u_1比u_2$好。</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fotp9srn5zj30er0b33yh.jpg" alt=""></p><p>为什么$u_1比u_2$好呢？可以有两种解释，第一种解释是样本点到这个直线的距离足够近，第二种解释是样本点在这个直线上的投影能尽可能的分开。</p><p>假如我们把n’从1维推广到任意维，则我们的希望降维的标准为：样本点到这个超平面的距离足够近,或者说样本点在这个超平面上的投影能尽可能的分开。</p><p>基于上面的两种标准，我们可以得到PCA的两种等价推导。</p><h3 id="2-PCA的推导-基于小于投影距离"><a href="#2-PCA的推导-基于小于投影距离" class="headerlink" title="2. PCA的推导:基于小于投影距离"></a>2. PCA的推导:基于小于投影距离</h3><p>我们首先看第一种解释的推导，即样本点到这个超平面的距离足够近。</p><p>假设m个n维数据($(x^{(1)}, x^{(2)},…,x^{(m)})$都已经进行了标准化，即$\sum\limits_{i=1}^{m}x^{(i)}=0$。经过投影变换后得到的新坐标系为${w_1,w_2,…,w_n}$,其中$w$是标准正交基，即$||w||_2=1, w_i^Tw_j=0$。</p><p>如果我们将数据从n维降到n’维，即丢弃新坐标系中的部分坐标，则新的坐标系为${w_1,w_2,…,w_{n’}}$,样本点$x^{(i)}$在n’维坐标系中的投影为：$z^{(i)} = (z_1^{(i)}, z_2^{(i)},…,z_{n’}^{(i)})$.其中，$z_j^{(i)} = w_j^Tx^{(i)}$是$x^{(i)}$在低维坐标系里第j维的坐标。</p><p>如果我们用$z^{(i)}$来恢复原始数据$x^{(i)}$,则得到的恢复数据$\overline{x}^{(i)} = \sum\limits_{j=1}^{n’}z_j^{(i)}w_j = Wz^{(i)}$,其中，W为标准正交基组成的矩阵。</p><p>现在我们考虑整个样本集，我们希望所有的样本到这个超平面的距离足够近，即最小化下式：<br>$$<br>\sum\limits_{i=1}^{m}||\overline{x}^{(i)} - x^{(i)}||_2^2<br>$$<br>将这个式子进行整理，可以得到:<br>$$<br> \begin{align} \sum\limits_{i=1}^{m}||\overline{x}^{(i)} - x^{(i)}||_2^2 &amp; = \sum\limits_{i=1}^{m}|| Wz^{(i)} - x^{(i)}||_2^2 \\&amp; = \sum\limits_{i=1}^{m}(Wz^{(i)})^T(Wz^{(i)}) - 2\sum\limits_{i=1}^{m}(Wz^{(i)})^Tx^{(i)} + \sum\limits_{i=1}^{m} x^{(i)T}x^{(i)} \\&amp; = \sum\limits_{i=1}^{m}z^{(i)T}z^{(i)} - 2\sum\limits_{i=1}^{m}z^{(i)T}W^Tx^{(i)} +\sum\limits_{i=1}^{m} x^{(i)T}x^{(i)} \\&amp; = \sum\limits_{i=1}^{m}z^{(i)T}z^{(i)} - 2\sum\limits_{i=1}^{m}z^{(i)T}z^{(i)}+\sum\limits_{i=1}^{m} x^{(i)T}x^{(i)} \\&amp; = - \sum\limits_{i=1}^{m}z^{(i)T}z^{(i)} + \sum\limits_{i=1}^{m} x^{(i)T}x^{(i)} \\&amp; = -tr( W^T（\sum\limits_{i=1}^{m}x^{(i)}x^{(i)T})W) + \sum\limits_{i=1}^{m} x^{(i)T}x^{(i)} \\&amp; = -tr( W^TXX^TW) + \sum\limits_{i=1}^{m} x^{(i)T}x^{(i)} \end{align}<br>$$<br>其中第（1）步用到了$\overline{x}^{(i)}=Wz^{(i)}$ ,第二步用到了平方和展开，第（3）步用到了矩阵转置公式$(AB)^T =B^TA^T$和$W^TW=I$,第（4）步用到了$z^{(i)}=W^Tx^{(i)}$，第（5）步合并同类项，第（6）步用到了$z^{(i)}=W^Tx^{(i)}$和矩阵的迹,第7步将代数和表达为矩阵形式。</p><p>注意到$\sum\limits_{i=1}^{m}x^{(i)}x^{(i)T}$是数据集的协方差矩阵，W的每一个向量$w_j$是标准正交基。而$\sum\limits_{i=1}^{m} x^{(i)T}x^{(i)}$是一个常量。最小化上式等价于：<br>$$<br>\underbrace{arg\;min}_{W}\;-tr( W^TXX^TW) \;\;s.t. W^TW=I<br>$$<br>这个最小化不难，直接观察也可以发现最小值对应的W由协方差矩阵$XX^T$最大的n’个特征值对应的特征向量组成。当然用数学推导也很容易。利用拉格朗日函数可以得到<br>$$<br>J(W) = -tr( W^TXX^TW) + \lambda(W^TW-I)<br>$$<br>对W求导有$-XX^TW+\lambda W=0$, 整理下即为：<br>$$<br>XX^TW=\lambda W<br>$$<br>这样可以更清楚的看出，W为$XX^T$的n’个特征向量组成的矩阵，而$\lambda$为$XX^T$的特征值。当我们将数据集从n维降到n’维时，需要找到最大的n’个特征值对应的特征向量。这n’个特征向量组成的矩阵W即为我们需要的矩阵。对于原始数据集，我们只需要用$z^{(i)}=W^Tx^{(i)}$,就可以把原始数据集降维到最小投影距离的n’维数据集。</p><p>如果你熟悉谱聚类的优化过程，就会发现和PCA的非常类似，只不过谱聚类是求前k个最小的特征值对应的特征向量，而PCA是求前k个最大的特征值对应的特征向量。　　</p><h3 id="3-PCA的推导-基于最大投影方差"><a href="#3-PCA的推导-基于最大投影方差" class="headerlink" title="3. PCA的推导:基于最大投影方差"></a>3. PCA的推导:基于最大投影方差</h3><p>现在我们再来看看基于最大投影方差的推导。</p><p>假设m个n维数据$(x^{(1)}, x^{(2)},…,x^{(m)})$都已经进行了标准化，即$\sum\limits_{i=1}^{m}x^{(i)}=0$。经过投影变换后得到的新坐标系${w_1,w_2,…,w_n}$,其中$w$是标准正交基，即$||w||_2=1, w_i^Tw_j=0$。</p><p>如果我们将数据从n维降到n’维，即丢弃新坐标系中的部分坐标，则新的坐标系为${w_1,w_2,…,w_{n’}}$,样本点$x^{(i)}$在n’维坐标系中的投影为：$z^{(i)} = (z_1^{(i)}, z_2^{(i)},…,z_{n’}^{(i)})$.其中，$z_j^{(i)} = w_j^Tx^{(i)}是x(i)x(i)x^{(i)}$在低维坐标系里第j维的坐标。</p><p>对于任意一个样本$x^{(i)}$，在新的坐标系中的投影为$W^Tx^{(i)}$,在新坐标系中的投影方差为$x^{(i)T}W^Tx^{(i)}W$，要使所有的样本的投影方差和最大，也就是最大化$\sum\limits_{i=1}^{m}x^{(i)T}W^Tx^{(i)}W$,即：<br>$$<br>\underbrace{arg\;max}_{W}\;tr( W^TXX^TW) \;\;s.t. W^TW=I<br>$$<br>观察第二节的基于最小投影距离的优化目标，可以发现完全一样，只是一个是加负号的最小化，一个是最大化。</p><p>利用拉格朗日函数可以得到<br>$$<br>J(W) = tr( W^TXX^TW) + \lambda(W^TW-I)<br>$$<br>对W求导有$XX^TW+\lambda W=0$, 整理下即为：<br>$$<br>XX^TW=（-\lambda）W<br>$$<br>和上面一样可以看出，W为$XX^T$的n’个特征向量组成的矩阵，而$-\lambda$为$XX^T$的特征值。当我们将数据集从n维降到n’维时，需要找到最大的n’个特征值对应的特征向量。这n’个特征向量组成的矩阵W即为我们需要的矩阵。对于原始数据集，我们只需要用$z^{(i)}=W^Tx^{(i)}$,就可以把原始数据集降维到最小投影距离的n’维数据集。</p><h3 id="4-PCA算法流程"><a href="#4-PCA算法流程" class="headerlink" title="4. PCA算法流程"></a>4. PCA算法流程</h3><p>从上面两节我们可以看出，求样本$x^{(i)}$的n’维的主成分其实就是求样本集的协方差矩阵$XX^T$的前n’个特征值对应特征向量矩阵W，然后对于每个样本$x^{(i)}$,做如下变换$z^{(i)}=W^Tx^{(i)}$，即达到降维的PCA目的。</p><p>下面我们看看具体的算法流程。</p><p>输入：n维样本集$D=(x^{(1)}, x^{(2)},…,x^{(m)})$，要降维到的维数n’.</p><p>输出：降维后的样本集$D’$</p><p>1) 对所有的样本进行中心化： $x^{(i)} = x^{(i)} - \frac{1}{m}\sum\limits_{j=1}^{m} x^{(j)}$</p><p>2) 计算样本的协方差矩阵$XX^T$</p><p>3) 对矩阵$XX^T$进行特征值分解</p><p>4）取出最大的n’个特征值对应的特征向量$(w_1,w_2,…,w_{n’})$, 将所有的特征向量标准化后，组成特征向量矩阵W。</p><p>5）对样本集中的每一个样本$x^{(i)}$,转化为新的样本$z^{(i)}=W^Tx^{(i)}$</p><p>6) 得到输出样本集$D’ =(z^{(1)}, z^{(2)},…,z^{(m)})$</p><p>有时候，我们不指定降维后的n’的值，而是换种方式，指定一个降维到的主成分比重阈值t。这个阈值t在（0,1]之间。假如我们的n个特征值为$\lambda_1 \geq \lambda_2 \geq … \geq \lambda_n$,则n’可以通过下式得到:<br>$$<br>\frac{\sum\limits_{i=1}^{n’}\lambda_i}{\sum\limits_{i=1}^{n}\lambda_i} \geq t<br>$$</p><h3 id="5-PCA实例"><a href="#5-PCA实例" class="headerlink" title="5. PCA实例"></a>5. PCA实例</h3><p>下面举一个简单的栗子🌰，说明PCA的过程。</p><p>假设我们的数据集有10个二维数据(2.5,2.4), (0.5,0.7), (2.2,2.9), (1.9,2.2), (3.1,3.0), (2.3, 2.7), (2, 1.6), (1, 1.1), (1.5, 1.6), (1.1, 0.9)，需要用PCA降到1维特征。</p><p>首先我们对样本中心化，这里样本的均值为(1.81, 1.91),所有的样本减去这个均值后，即中心化后的数据集为(0.69, 0.49), (-1.31, -1.21), (0.39, 0.99), (0.09, 0.29), (1.29, 1.09), (0.49, 0.79), (0.19, -0.31), (-0.81, -0.81), (-0.31, -0.31), (-0.71, -1.01)。</p><p>现在我们开始求样本的协方差矩阵，由于我们是二维的，则协方差矩阵为：</p><p>$$<br>\mathbf{XX^T} = \left( \begin{array}{ccc} cov(x_1,x_1) &amp; cov(x_1,x_2)\\ cov(x_2,x_1) &amp; cov(x_2,x_2) \end{array} \right)<br>$$<br>对于我们的数据，求出协方差矩阵为：<br>$$<br>\mathbf{XX^T} = \left( \begin{array}{ccc} 0.616555556 &amp; 0.615444444\\ 0.615444444 &amp; 0.716555556 \end{array} \right)<br>$$<br>求出特征值为（0.490833989， 1.28402771），对应的特征向量分别为：$(0.735178656, 0.677873399)^T\;\; (-0.677873399, -0.735178656)^T$,由于最大的k=1个特征值为1.28402771，对于的k=1个特征向量为$(-0.677873399, -0.735178656)^T$. 则我们的$W=(-0.677873399, -0.735178656)^T$</p><p>我们对所有的数据集进行投影$z^{(i)}=W^Tx^{(i)}$，得到PCA降维后的10个一维数据集为：(-0.827970186， 1.77758033， -0.992197494， -0.274210416， -1.67580142， -0.912949103， 0.0991094375， 1.14457216, 0.438046137， 1.22382056)</p><h3 id="6-核主成分分析KPCA介绍"><a href="#6-核主成分分析KPCA介绍" class="headerlink" title="6. 核主成分分析KPCA介绍"></a>6. 核主成分分析KPCA介绍</h3><p>在上面的PCA算法中，我们假设存在一个线性的超平面，可以让我们对数据进行投影。但是有些时候，数据不是线性的，不能直接进行PCA降维。这里就需要用到和支持向量机一样的核函数的思想，先把数据集从n维映射到线性可分的高维N&gt;n,然后再从N维降维到一个低维度n’, 这里的维度之间满足n’&lt;n&lt;N。</p><p>使用了核函数的主成分分析一般称之为核主成分分析(Kernelized PCA, 以下简称KPCA。假设高维空间的数据是由n维空间的数据通过映射$\phi$产生。</p><p>则对于n维空间的特征分解：<br>$$<br> \sum\limits_{i=1}^{m}x^{(i)}x^{(i)T}W=\lambda W<br>$$<br>映射为：<br>$$<br> \sum\limits_{i=1}^{m}\phi(x^{(i)})\phi(x^{(i)})^TW=\lambda W<br>$$<br>通过在高维空间进行协方差矩阵的特征值分解，然后用和PCA一样的方法进行降维。一般来说，映射$\phi$不用显式的计算，而是在需要计算的时候通过核函数完成。由于KPCA需要核函数的运算，因此它的计算量要比PCA大很多。</p><h3 id="7-白化whitening"><a href="#7-白化whitening" class="headerlink" title="7. 白化whitening"></a>7. <strong>白化whitening</strong></h3><h4 id="一、相关理论"><a href="#一、相关理论" class="headerlink" title="一、相关理论"></a><strong>一、相关理论</strong></h4><p>白化这个词，可能在深度学习领域比较常遇到，挺起来就是高大上的名词，然而其实白化是一个比PCA稍微高级一点的算法而已，所以如果熟悉PCA，那么其实会发现这是一个非常简单的算法。</p><p>白化的目的是去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；白化的目的就是降低输入的冗余性。</p><p>输入数据集X，经过白化处理后，新的数据X’满足两个性质：</p><p>(1)特征之间相关性较低；</p><p>(2)所有特征具有相同的方差。</p><p>其实我们之前学的PCA算法中，可能PCA给我们的印象是一般用于降维操作。然而其实PCA如果不降维，而是仅仅使用PCA求出特征向量，然后把数据X映射到新的特征空间，这样的一个映射过程，其实就是满足了我们白化的第一个性质：除去特征之间的相关性。因此白化算法的实现过程，第一步操作就是PCA，求出新特征空间中X的新坐标，然后再对新的坐标进行方差归一化操作。</p><h4 id="二、算法概述"><a href="#二、算法概述" class="headerlink" title="二、算法概述"></a><strong>二、算法概述</strong></h4><p>白化分为PCA白化、ZCA白化，下面主要讲解算法实现。这部分主要是学了UFLDL的深度学习《白化》教程：<a href="http://ufldl.stanford.edu/wiki/index.php/%E7%99%BD%E5%8C%96" target="_blank" rel="noopener">http://ufldl.stanford.edu/wiki/index.php/%E7%99%BD%E5%8C%96</a> 。自己的一点概括总结，算法实现步骤如下：</p><h5 id="1、首先是PCA预处理"><a href="#1、首先是PCA预处理" class="headerlink" title="1、首先是PCA预处理"></a><strong>1、首先是PCA预处理</strong></h5><p><img src="http://img.blog.csdn.net/20160312120157759" alt=""> <img src="http://img.blog.csdn.net/20160312120205309" alt=""></p><p>上面图片，左图表示原始数据X，然后我们通过协方差矩阵可以求得特征向量u1、u2，然后把每个数据点，投影到这两个新的特征向量，得到进行坐标如下：</p><p><img src="http://img.blog.csdn.net/20160312120214088" alt=""></p><p>这就是所谓的pca处理。</p><h5 id="2、PCA白化"><a href="#2、PCA白化" class="headerlink" title="2、PCA白化"></a><strong>2、PCA白化</strong></h5><p>所谓的pca白化是指对上面的pca的新坐标X’,每一维的特征做一个标准差归一化处理。因为从上面我们看到在新的坐标空间中，(x1,x2)两个坐标轴方向的数据明显标准差不同，因此我们接着要对新的每一维坐标做一个标注差归一化处理：</p><p><img src="http://img.blog.csdn.net/20160312121312585" alt=""></p><p>当然你也可以采用下面的公式：</p><p><img src="http://img.blog.csdn.net/20160312121413148" alt=""></p><p>X’为经过PCA处理的新PCA坐标空间,然后λi就是第i维特征对应的特征值（前面pca得到的特征值），ε是为了避免除数为0。</p><p><img src="http://img.blog.csdn.net/20160312121102984" alt=""></p><h5 id="3、ZCA白化"><a href="#3、ZCA白化" class="headerlink" title="3、ZCA白化"></a><strong>3、ZCA白化</strong></h5><p>ZCA白虎是在PCA白化的基础上，又进行处理的一个操作。具体的实现是把上面PCA白化的结果，又变换到原来坐标系下的坐标：</p><p><img src="http://img.blog.csdn.net/20160312121828206" alt=""></p><p>给人的感觉就像是在PCA空间做了处理完后，然后又把它变换到原始的数据空间。</p><p><img src="http://img.blog.csdn.net/20160312121921531" alt=""></p><p>具体源码实现如下：</p><pre><code>def zca_whitening(inputs):
    sigma = np.dot(inputs, inputs.T)/inputs.shape[1] #inputs是经过归一化处理的，所以这边就相当于计算协方差矩阵
    U,S,V = np.linalg.svd(sigma) #奇异分解
    epsilon = 0.1                #白化的时候，防止除数为0
    ZCAMatrix = np.dot(np.dot(U, np.diag(1.0/np.sqrt(np.diag(S) + epsilon))), U.T)                     #计算zca白化矩阵
    return np.dot(ZCAMatrix, inputs)   #白化变换
</code></pre><h3 id="8-PCA算法总结"><a href="#8-PCA算法总结" class="headerlink" title="8. PCA算法总结"></a>8. PCA算法总结</h3><p>这里对PCA算法做一个总结。作为一个非监督学习的降维方法，它只需要特征值分解，就可以对数据进行压缩，去噪。因此在实际场景应用很广泛。为了克服PCA的一些缺点，出现了很多PCA的变种，比如第六节的为解决非线性降维的KPCA，还有解决内存限制的增量PCA方法Incremental PCA，以及解决稀疏数据降维的PCA方法Sparse PCA等。</p><p>PCA算法的主要优点有：</p><p>1）仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　</p><p>2）各主成分之间正交，可消除原始数据成分间的相互影响的因素。</p><p>3）计算方法简单，主要运算是特征值分解，易于实现。</p><p>PCA算法的主要缺点有：</p><p>1）主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。</p><p>2）方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</p><blockquote style="margin:2em 0 0;padding:.5em 1em;border-left:3px solid #f44336;background-color:#f5f5f5;list-style:none"><p> <strong>This blog is under a <a href="https://pancakeawesome.ink/" target="_blank">CC BY-NC-SA 3.0 Unported License</a></strong><br> <strong>本文链接：</strong><a href="http://pancakeawesome.ink/主成分分析（PCA）原理总结.html">http://pancakeawesome.ink/主成分分析（PCA）原理总结.html</a></p></blockquote></div><div id="changyan-comment"><div id="SOHUCS" sid="主成分分析（PCA）原理总结.html"></div><script type="text/javascript">!function(){var t="da223e602e0abf03eded8d4c19e7d862";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=cytdf2o7Q&conf='+t+'"><\/script>');else{!function(t,e){var n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,a=document.createElement("script");a.setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:"cytdf2o7Q",conf:t})})}}()</script></div><style>#changyan-comment{background-color:#eee;padding:2pc}</style></div><nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col"> <a href="/深度神经网络(DNN)模型与前向传播算法(FP).html" id="post_nav-newer" class="prev-content"><button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_back</i></button> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 新篇</a><div class="section-spacer"></div> <a href="/K-Means聚类算法原理.html" id="post_nav-older" class="next-content">旧篇 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_forward</i></button></a></nav></div></div><div class="sidebar-overlay"></div><aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation"><div id="sidebar-main"><div class="sidebar-header header-cover" style="background-image:url(/img/thumbnail/sidebar_header.jpg)"><div class="top-bar"></div> <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display:initial" data-upgraded=",MaterialButton,MaterialRipple"> <i class="material-icons">clear_all</i><span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></button><div class="sidebar-image"> <img src="/img/rip.jpeg" alt="Edward Guan's avatar"></div> <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">guanchao930908@163.com<b class="caret"></b></a></div><ul class="nav sidebar-nav"><li class="dropdown"><ul id="settings-dropdown" class="dropdown-menu"><li> <a href="mailto:guanchao930908@163.com" target="_blank" title="Email Me"><i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i> Email Me</a></li></ul></li><li id="sidebar-first-li"> <a href="/"><i class="material-icons sidebar-material-icons">home</i> 主页</a></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">timeline</i> 归档<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">11</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/02/">二月 2018<span class="sidebar_archives-count">16</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">13</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/10/">十月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">10</span></a></li></ul></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">chrome_reader_mode</i> 分类<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/categories/OCR/">OCR<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/blog/">blog<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/categories/javascript/">javascript<span class="sidebar_archives-count">12</span></a></li><li><a class="sidebar_archives-link" href="/categories/nodejs/">nodejs<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/react/">react<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端工具/">前端工具<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端技术/">前端技术<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据分析/">数据分析<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据可视化/">数据可视化<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/机器学习/">机器学习<span class="sidebar_archives-count">18</span></a></li><li><a class="sidebar_archives-link" href="/categories/深度学习/">深度学习<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/categories/目标检测/">目标检测<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/算法思想/">算法思想<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/计算机网络/">计算机网络<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/论文笔记/">论文笔记<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/软件开发/">软件开发<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/面试/">面试<span class="sidebar_archives-count">1</span></a></li></ul></li><li> <a href="/tags" title="标签云"><i class="material-icons sidebar-material-icons">cloud_circle</i> 标签云</a></li><li class="divider"></li><li> <a href="/timeline" title="Timeline"><i class="material-icons sidebar-material-icons">send</i> Timeline</a></li><li> <a href="/gallery" title="Gallery"><i class="material-icons sidebar-material-icons">photo_library</i> Gallery</a></li><li> <a href="/aboutMe" title="About Me"><i class="material-icons sidebar-material-icons">person_pin</i> About Me</a></li><li class="divider"></li><li> <a href="/archives">文章总数 <span class="sidebar-badge">90</span></a></li></ul></div></aside><div id="back-to-top" class="toTop-wrap"> <a href="#top" class="toTop"><i class="material-icons footer_top-i">expand_less</i></a></div><footer class="mdl-mini-footer" id="bottom"><div class="mdl-mini-footer--left-section sns-list"> <a href="https://twitter.com/591153977" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-twitter"> <span class="visuallyhidden">Twitter</span></button></a> <a href="https://www.facebook.com/profile.php?id=100011433530812" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-facebook"> <span class="visuallyhidden">Facebook</span></button></a> <a href="https://www.instagram.com/edward930908/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-instagram"> <span class="visuallyhidden">Instagram</span></button></a> <a href="https://github.com/PancakeAwesome" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-github"> <span class="visuallyhidden">Github</span></button></a> <a href="https://www.linkedin.com/in/%E8%B6%85-%E7%AE%A1-89495a145/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-linkedin"> <span class="visuallyhidden">LinkedIn</span></button></a></div><div id="copyright"> Copyright&nbsp;©<script type="text/javascript">var fd=new Date;document.write("&nbsp;"+fd.getFullYear()+"&nbsp;")</script>Edward's Blog<br><p>Hosted by <a href="https://pages.coding.me" style="font-weight:700">Coding Pages</a></p></div><div class="mdl-mini-footer--right-section"><div><div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div><div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div></div></div></footer><script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==",!0)</script><script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==",!0)</script><script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==",!0)</script><script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><script id="cy_cmt_num" src="https://changyan.sohu.com/upload/plugins/plugins.list.count.js?clientId=cytdf2o7Q"></script><script>var agent=navigator.userAgent.toLowerCase();agent.indexOf("ucbrowser")>0&&(document.write('<link rel="stylesheet" href="/css/uc.css">'),alert("由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。"))</script><script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==",!0)</script><script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script><script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script><script>!function(){for(var e=document.querySelectorAll('script[type="text/ls-javascript"]'),r=0;r<e.length;++r){var o=e[r];lsloader.runInlineScript(o.id,o.id)}}(),console.log("\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;")</script></main></div><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>