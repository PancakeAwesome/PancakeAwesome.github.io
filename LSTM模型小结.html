<!DOCTYPE html><html style="display:none" lang="zh"><head><meta charset="utf-8"><script>window.materialVersion="1.5.0",window.oldVersion=["codestartv1","1.3.4","1.4.0","1.4.0b1"]</script><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://busuanzi.ibruce.info"><link rel="dns-prefetch" href="https://changyan.sohu.com"><title> LSTM模型小结 | Edward&#39;s Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0097A7"><meta name="author" content="Edward Guan"><meta name="description" itemprop="description" content="LSTM模型小结"><meta name="keywords" content="前端,node,react,js,java,自学编程,学习分享,UESTC,深度学习"><script>window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}},lsloader.removeLS=function(e){try{localStorage.removeItem(e)}catch(e){}},lsloader.setLS=function(e,t){try{localStorage.setItem(e,t)}catch(e){}},lsloader.getLS=function(e){var t="";try{t=localStorage.getItem(e)}catch(e){t=""}return t},versionString="/*"+(window.materialVersion||"unknownVersion")+"*/",lsloader.clean=function(){try{for(var e=[],t=0;t<localStorage.length;t++)e.push(localStorage.key(t));e.forEach(function(e){var t=lsloader.getLS(e);window.oldVersion&&window.oldVersion.reduce(function(e,n){return e||-1!==t.indexOf("/*"+n+"*/")},!1)&&lsloader.removeLS(e)})}catch(e){}},lsloader.clean(),lsloader.load=function(e,t,n,s){"boolean"==typeof n&&(s=n,n=void 0),s=s||!1,n=n||function(){};var a;if((a=this.getLS(e))&&-1===a.indexOf(versionString))return this.removeLS(e),void this.requestResource(e,t,n,s);if(a){if(a.split(versionString)[0]!=t)return console.log("reload:"+t),this.removeLS(e),void this.requestResource(e,t,n,s);a=a.split(versionString)[1],s?(this.jsRunSequence.push({name:e,code:a}),this.runjs(t,e,a)):(document.getElementById(e).appendChild(document.createTextNode(a)),n())}else this.requestResource(e,t,n,s)},lsloader.requestResource=function(e,t,n,s){var a=this;s?this.iojs(t,e,function(e,t,n){a.setLS(t,e+versionString+n),a.runjs(e,t,n)}):this.iocss(t,e,function(n){document.getElementById(e).appendChild(document.createTextNode(n)),a.setLS(e,t+versionString+n)},n)},lsloader.iojs=function(e,t,n){var s=this;s.jsRunSequence.push({name:t,code:""});try{var a=new XMLHttpRequest;a.open("get",e,!0),a.onreadystatechange=function(){if(4==a.readyState){if((a.status>=200&&a.status<300||304==a.status)&&""!=a.response)return void n(e,t,a.response);s.jsfallback(e,t)}},a.send(null)}catch(n){s.jsfallback(e,t)}},lsloader.iocss=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.iofonts=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.runjs=function(e,t,n){if(t&&n)for(var s in this.jsRunSequence)this.jsRunSequence[s].name==t&&(this.jsRunSequence[s].code=n);if(this.jsRunSequence[0]&&this.jsRunSequence[0].code&&"failed"!=this.jsRunSequence[0].status)(o=document.createElement("script")).appendChild(document.createTextNode(this.jsRunSequence[0].code)),o.type="text/javascript",document.getElementsByTagName("head")[0].appendChild(o),this.jsRunSequence.shift(),this.jsRunSequence.length>0&&this.runjs();else if(this.jsRunSequence[0]&&"failed"==this.jsRunSequence[0].status){var a=this,o=document.createElement("script");o.src=this.jsRunSequence[0].path,o.type="text/javascript",this.jsRunSequence[0].status="loading",o.onload=function(){a.jsRunSequence.shift(),a.jsRunSequence.length>0&&a.runjs()},document.body.appendChild(o)}},lsloader.tagLoad=function(e,t){this.jsRunSequence.push({name:t,code:"",path:e,status:"failed"}),this.runjs()},lsloader.jsfallback=function(e,t){if(!this.jsnamemap[t]){this.jsnamemap[t]=t;for(var n in this.jsRunSequence)this.jsRunSequence[n].name==t&&(this.jsRunSequence[n].code="",this.jsRunSequence[n].status="failed",this.jsRunSequence[n].path=e);this.runjs()}},lsloader.cssfallback=function(e,t,n){if(!this.cssnamemap[t]){this.cssnamemap[t]=1;var s=document.createElement("link");s.type="text/css",s.href=e,s.rel="stylesheet",s.onload=s.onerror=n;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(s,a)}},lsloader.runInlineScript=function(e,t){var n=document.getElementById(t).innerText;this.jsRunSequence.push({name:e,code:n}),this.runjs()},lsloader.loadCombo=function(e){var t="",n={};for(var s in e){var a=this.getLS(e[s].name);if(a)var o=a.split(versionString)[0],i=a.split(versionString)[1];else o="";o==e[s].path?this.jsRunSequence.push({name:e[s].name,code:i,path:e[s].path}):(this.jsRunSequence.push({name:e[s].name,code:null,path:e[s].path,status:"comboloading"}),n[e[s].name]=!0,t+=(""==t?"":";")+e[s].path)}var u=this;if(t){var r=new XMLHttpRequest;r.open("get",combo+t,!0),r.onreadystatechange=function(){if(4==r.readyState)if(r.status>=200&&r.status<300||304==r.status){if(""!=r.response)return void u.runCombo(r.response,n)}else{for(var e in u.jsRunSequence)n[u.jsRunSequence[e].name]&&(u.jsRunSequence[e].status="failed");u.runjs()}},r.send(null)}this.runjs()},lsloader.runCombo=function(e,t){(e=e.split("/*combojs*/")).shift();for(var n in this.jsRunSequence)t[this.jsRunSequence[n].name]&&e[0]&&(this.jsRunSequence[n].status="comboJS",this.jsRunSequence[n].code=e[0],this.setLS(this.jsRunSequence[n].name,this.jsRunSequence[n].path+versionString+e[0]),e.shift());this.runjs()}</script><script>function Queue(){this.dataStore=[],this.offer=function(e){this.debug&&console.log("Offered a Queued Function."),"function"==typeof e?this.dataStore.push(e):console.log("You must offer a function.")},this.poll=function(){return this.debug&&console.log("Polled a Queued Function."),this.dataStore.shift()},this.execNext=function(){var e=this.poll();void 0!==e&&(this.debug&&console.log("Run a Queued Function."),e())},this.debug=!1,this.startDebug=function(){this.debug=!0}}var queue=new Queue</script><link rel="icon shortcut" type="image/ico" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="icon" sizes="192x192" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="apple-touch-icon" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="apple-mobile-web-app-title" content="Title"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="480"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="apple-mobile-web-app-title" content="Edward&#39;s Blog"> <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie-blocker.css"><script src="/js/ie-blocker.zhCN.js"></script><![endif]--><style id="material_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="style_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_theme"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_theme","/css/prettify/github-v2.min.css?AfzKxt++K+/lhZBlSjnxwg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style>body,html{font-family:Roboto,"Helvetica Neue",Helvetica,"PingFang SC","Hiragino Sans GB","Microsoft YaHei","微软雅黑",Arial,sans-serif;overflow-x:hidden!important}code{font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace}a{color:#00838f}#scheme-Paradox .hot_tags-count,#scheme-Paradox .sidebar-colored .sidebar-badge,#scheme-Paradox .sidebar-colored .sidebar-header,#scheme-Paradox .sidebar_archives-count,#search-form-label:after,#search-label,.mdl-card__media{background-color:#0097a7!important}#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus,#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover{color:#0097a7!important}#ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a,#post_entry-right-info,.sidebar-colored .sidebar-nav li:hover>a,.sidebar-colored .sidebar-nav li:hover>a i,.sidebar-colored .sidebar-nav li>a:focus i,.sidebar-colored .sidebar-nav li>a:hover,.sidebar-colored .sidebar-nav li>a:hover i,.sidebar-colored .sidebar-nav>.open>a,.sidebar-colored .sidebar-nav>.open>a:focus,.sidebar-colored .sidebar-nav>.open>a:hover{color:#0097a7!important}.toTop{background:#757575!important}.material-layout .material-index>.material-nav,.material-layout .material-post>.material-nav,.material-nav a{color:#757575}#scheme-Paradox .MD-burger-layer{background-color:#757575}#scheme-Paradox #post-toc-trigger-btn{color:#757575}.post-toc a:hover{color:#00838f;text-decoration:underline}</style><style>body{background-color:#f5f5f5}#scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{background-color:#fff}</style><style>.fade{transition:all .8s linear;-webkit-transform:translate3d(0,0,0);-moz-transform:translate3d(0,0,0);-ms-transform:translate3d(0,0,0);-o-transform:translate3d(0,0,0);transform:translate3d(0,0,0);opacity:1}.fade.out{opacity:0}</style><link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet"><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"><script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==",!0)</script><meta property="og:url" content="http://pancakeawesome.ink"><meta property="og:type" content="blog"><meta property="og:title" content="LSTM模型小结 | Edward&#39;s Blog"><meta property="og:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta property="og:description" content="LSTM模型小结"><meta property="og:article:tag" content="深度学习"><meta property="article:published_time" content="Tue Apr 17 2018 21:12:30 GMT+0800"><meta property="article:modified_time" content="Tue Apr 24 2018 21:58:59 GMT+0800"><meta name="twitter:title" content="LSTM模型小结 | Edward&#39;s Blog"><meta name="twitter:description" content="LSTM模型小结"><meta name="twitter:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="http://pancakeawesome.ink"><link rel="canonical" href="http://pancakeawesome.ink/LSTM模型小结.html"><script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://pancakeawesome.ink/LSTM模型小结.html",
    "headline": "LSTM模型小结",
    "datePublished": "Tue Apr 17 2018 21:12:30 GMT+0800",
    "dateModified": "Tue Apr 24 2018 21:58:59 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Edward Guan",
        "image": {
            "@type": "ImageObject",
            "url": "/img/rip.jpeg"
        },
        "description": "你说人生艳丽我没有异议，你说人生忧郁我不言语"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Edward&#39;s Blog",
        "logo": {
            "@type":"ImageObject",
            "url": "http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"
        }
    },
    "keywords": ",深度学习前端,node,react,js,java,自学编程,学习分享,UESTC",
    "description": "LSTM模型小结",
}
</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0c041dca6f79c4e40fb45d1283e327e7";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body id="scheme-Paradox" class="lazy"><div class="material-layout mdl-js-layout has-drawer is-upgraded"><main class="material-layout__content" id="main"><div id="top"></div> <button class="MD-burger-icon sidebar-toggle"><span class="MD-burger-layer"></span></button> <button id="post-toc-trigger-btn" class="mdl-button mdl-js-button mdl-button--icon"> <i class="material-icons">format_list_numbered</i></button><ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh;overflow-y:scroll"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#前言"><span class="post-toc-number">1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#LSTM模型小结"><span class="post-toc-number">2.</span> <span class="post-toc-text">LSTM模型小结</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1-从RNN到LSTM"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">1. 从RNN到LSTM</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-LSTM模型结构剖析"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">2. LSTM模型结构剖析</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-1-LSTM之遗忘门"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">2.1 LSTM之遗忘门</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-2-LSTM之输入门"><span class="post-toc-number">2.2.2.</span> <span class="post-toc-text">2.2 LSTM之输入门</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-3-LSTM之细胞状态更新"><span class="post-toc-number">2.2.3.</span> <span class="post-toc-text">2.3 LSTM之细胞状态更新</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-4-LSTM之输出门"><span class="post-toc-number">2.2.4.</span> <span class="post-toc-text">2.4 LSTM之输出门</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-LSTM重要分析"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">3. LSTM重要分析</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#4-LSTM前向传播算法"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">4. LSTM前向传播算法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#5-LSTM反向传播算法推导关键点"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">5. LSTM反向传播算法推导关键点</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#6-LSTM的正则化"><span class="post-toc-number">2.6.</span> <span class="post-toc-text">6. LSTM的正则化</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#后记"><span class="post-toc-number">3.</span> <span class="post-toc-text">后记</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#7-LSTM小结"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">7. LSTM小结</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#参考资料："><span class="post-toc-number">3.2.</span> <span class="post-toc-text">参考资料：</span></a></li></ol></li></ol></ul><div class="material-post_container"><div class="material-post mdl-grid"><div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col"><div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50"><script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 30 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script><p class="article-headline-p"> LSTM模型小结</p></div><div class="mdl-color-text--grey-700 mdl-card__supporting-text meta"><div id="author-avatar"> <img src="/img/rip.jpeg" width="44px" height="44px" alt="Author Avatar"></div><div> <strong>Edward Guan</strong> <span>4月 17, 2018</span></div><div class="section-spacer"></div> <button id="article-functions-qrcode-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">devices other</i> <span class="visuallyhidden">devices other</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-qrcode-button"><li class="mdl-menu__item">在其它设备中阅读本文章</li> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACYUlEQVR42u3aUY6DMAwFwN7/0t0DVLDPNgkIDV+o3TaZrERS+32+r74+eHh4eHh4eHh4D+N94qs8zM9nj175vZ/MDQ8PD28PL5lo9d2j6R5NvTru4Sh4eHh4G3lHQyYP997Uq9vG+d/g4eHhPZl3NKF8Yzin4uHh4b2VNyoZJBPFw8PDezwv+cF/1UR7hd3ltRY8PDy8mJc/1vffb+3v4eHh4QW8SSCguklUl++C0BUeHh7eAl51+F4Tq1rO6M0HDw8Pbw+v2taaBAiSTSVpiRXKuHh4eHgLeMlxNo9V9Rpg86M5Hh4e3l28JAiVbwxXLdD5whV+MeDh4eEt4FWbUtWA1KTUWwgT4OHh4S3m5eWGagmjtyiTWAMeHh7eHl61ZdWbUA9c3XLw8PDw9vOSgkJ+4I6Ov8Vxm6ErPDw8vAW8fPhrS669UZrRATw8PLyLePnDOj9MT5pek+M+Hh4e3h5efoCuhqjmTbLqgR4PDw9vD6+3MeRLkCzE5Phejg7g4eHhjXm9gmz+QM/jVvOwFx4eHt5OXq/pdf6p6gI1I1Z4eHh4N/HyEFX+qeoo3+JVCF3h4eHhLeNdW2CtFiwmgS08PDy8u3h5az8pOqxYgugfgIeHh7eY1zvITgIH+TcsiQ7g4eHhjXmTA+7qAFb1Hg8PD28nLy+Y9sIBk8XCw8PDezLv2gd08novQDDq7+Hh4eHdxJu/Ui095MuHh4eH90xecl9tYuWR1n9+AODh4eFt5OVRgGpcICleTAoZeHh4ePt51RLApMUVlWKL34+Hh4e3k/e+Cw8PDw8PDw8P7wHXHxkykGxUBcdxAAAAAElFTkSuQmCC"></ul> <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">bookmark</i> <span class="visuallyhidden">bookmark</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button"><li class="mdl-menu__item"> <a class="post_tag-link" href="/tags/深度学习/">深度学习</a></li></ul> <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">share</i> <span class="visuallyhidden">share</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button"><a class="post_share-link" href="#"><li class="mdl-menu__item"><span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span> &nbsp;浏览量</span></li></a><a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=LSTM模型小结&url=http://pancakeawesome.ink/LSTM模型小结.html&pic=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&searchPic=false&style=simple" target="_blank"><li class="mdl-menu__item"> 分享到微博</li></a><a class="post_share-link" href="https://twitter.com/intent/tweet?text=LSTM模型小结&url=http://pancakeawesome.ink/LSTM模型小结.html&via=Edward Guan" target="_blank"><li class="mdl-menu__item"> 分享到 Twitter</li></a><a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://pancakeawesome.ink/LSTM模型小结.html" target="_blank"><li class="mdl-menu__item"> 分享到 Facebook</li></a><a class="post_share-link" href="https://plus.google.com/share?url=http://pancakeawesome.ink/LSTM模型小结.html" target="_blank"><li class="mdl-menu__item"> 分享到 Google+</li></a><a class="post_share-link" href="https://www.linkedin.com/shareArticle?mini=true&url=http://pancakeawesome.ink/LSTM模型小结.html&title=LSTM模型小结" target="_blank"><li class="mdl-menu__item"> 分享到 LinkedIn</li></a><a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Edward&#39;s Blog&title=LSTM模型小结&summary=技术分享,学习笔记&pics=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&url=http://pancakeawesome.ink/LSTM模型小结.html" target="_blank"><li class="mdl-menu__item"> 分享到 QQ</li></a></ul></div><div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="http://pancakeawesome.ink/RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B0%8F%E7%BB%93.html">循环神经网络(RNN)模型与前向反向传播算法</a>中，我们总结了对RNN模型做了总结。由于RNN也有梯度消失的问题，因此很难处理长序列的数据，大牛们对RNN做了改进，得到了RNN的特例LSTM（Long Short-Term Memory），它可以避免常规RNN的梯度消失，因此在工业界得到了广泛的应用。下面我们就对LSTM模型做一个总结。</p><h2 id="LSTM模型小结"><a href="#LSTM模型小结" class="headerlink" title="LSTM模型小结"></a>LSTM模型小结</h2><h3 id="1-从RNN到LSTM"><a href="#1-从RNN到LSTM" class="headerlink" title="1. 从RNN到LSTM"></a>1. 从RNN到LSTM</h3><p>在RNN模型里，我们讲到了RNN具有如下的结构，每个序列索引位置t都有一个隐藏状态$h^{(t)}$。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fqfyodn6eqj30hw0bkwew.jpg" alt=""></p><p>如果我们略去每层都有的$o^{(t)}, L^{(t)}, y^{(t)}$，则RNN的模型可以简化成如下图的形式：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fqfyp7w4m2j30ld082dfw.jpg" alt=""></p><p>图中可以很清晰看出在隐藏状态$h^{(t)}$由$x^{(t)}$和$h^{(t-1)}$得到。得到$h^{(t)}$后一方面用于当前层的模型损失计算，另一方面用于计算下一层的$h^{(t+1)}$。</p><p>由于RNN梯度消失的问题，大牛们对于序列索引位置t的隐藏结构做了改进，可以说通过一些技巧让隐藏结构复杂了起来，来避免梯度消失的问题，这样的特殊RNN就是我们的LSTM。由于LSTM有很多的变种，这里我们以最常见的LSTM为例讲述。LSTM的结构如下图：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fqfypi8975j30l0082mxc.jpg" alt=""></p><p>可以看到LSTM的结构要比RNN的复杂的多，真佩服牛人们怎么想出来这样的结构，然后这样居然就可以解决RNN梯度消失的问题？由于LSTM怎么可以解决梯度消失是一个比较难讲的问题，我也不是很熟悉，这里就不多说，重点回到LSTM的模型本身。</p><h3 id="2-LSTM模型结构剖析"><a href="#2-LSTM模型结构剖析" class="headerlink" title="2. LSTM模型结构剖析"></a>2. LSTM模型结构剖析</h3><p>上面我们给出了LSTM的模型结构，下面我们就一点点的剖析LSTM模型在每个序列索引位置t时刻的内部结构。</p><p>从上图中可以看出，在每个序列索引位置t时刻向前传播的除了和RNN一样的隐藏状态$h^{(t)}$，还多了另一个隐藏状态，如图中上面的长横线。这个隐藏状态我们一般称为细胞状态(Cell State)，记为$C^{(t)}$。如下图所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fqfypqwauqj30aj06ewec.jpg" alt=""></p><p>除了细胞状态，LSTM图中还有了很多奇怪的结构，这些结构一般称之为门控结构(Gate)。LSTM在在每个序列索引位置t的门一般包括遗忘门，输入门和输出门三种。下面我们就来研究上图中LSTM的遗忘门，输入门和输出门以及细胞状态。</p><h4 id="2-1-LSTM之遗忘门"><a href="#2-1-LSTM之遗忘门" class="headerlink" title="2.1 LSTM之遗忘门"></a>2.1 LSTM之遗忘门</h4><p>遗忘门（forget gate）顾名思义，是控制是否遗忘的，在LSTM中即以一定的概率控制是否遗忘上一层的隐藏细胞状态。遗忘门子结构如下图所示：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fqfypvknjkj30aj06g0sl.jpg" alt=""></p><p>图中输入的有上一序列的隐藏状态$h^{(t-1)}$和本序列数据$x^{(t)}$，通过一个激活函数，一般是sigmoid，得到遗忘门的输出$f^{(t)}$。由于sigmoid的输出$f^{(t)}$在[0,1]之间，因此这里的输出$f^{(t)}$代表了遗忘上一层隐藏细胞状态的概率。用数学表达式即为：<br>$$<br>f^{(t)} = \sigma(W_fh^{(t-1)} + U_fx^{(t)} + b_f)<br>$$<br>其中$W_f, U_f, b_f$为线性关系的系数和偏倚，和RNN中的类似。$\sigma$为sigmoid激活函数。</p><h4 id="2-2-LSTM之输入门"><a href="#2-2-LSTM之输入门" class="headerlink" title="2.2 LSTM之输入门"></a>2.2 LSTM之输入门</h4><p>输入门（input gate）负责处理当前序列位置的输入，它的子结构如下图：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fqfypznv7mj30ax06edfp.jpg" alt=""></p><p>从图中可以看到输入门由两部分组成，第一部分使用了sigmoid激活函数，输出为$i^{(t)}$,第二部分使用了tanh激活函数，输出为$a^{(t)}$, 两者的结果后面会相乘再去更新细胞状态。用数学表达式即为：<br>$$<br>i^{(t)} = \sigma(W_ih^{(t-1)} + U_ix^{(t)} + b_i)<br>$$<br>$$<br>a^{(t)} =tanh(W_ah^{(t-1)} + U_ax^{(t)} + b_a)<br>$$<br>其中$W_i, U_i, b_i, W_a, U_a, b_a,$为线性关系的系数和偏倚，和RNN中的类似。$\sigma$为sigmoid激活函数。</p><h4 id="2-3-LSTM之细胞状态更新"><a href="#2-3-LSTM之细胞状态更新" class="headerlink" title="2.3 LSTM之细胞状态更新"></a>2.3 LSTM之细胞状态更新</h4><p>在研究LSTM输出门之前，我们要先看看LSTM之细胞状态。前面的遗忘门和输入门的结果都会作用于细胞状态$C^{(t)}$。我们来看看从细胞状态$C^{(t-1)}$如何得到$C^{(t)}$。如下图所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fqfyqb4tzej30am06ct8l.jpg" alt=""></p><p>细胞状态$C^{(t)}$由两部分组成，第一部分是$C^{(t-1)}$和遗忘门输出$f^{(t)}$的乘积，第二部分是输入门的$i^{(t)}$和$a^{(t)}$的乘积，即：<br>$$<br>C^{(t)} = C^{(t-1)} \odot f^{(t)} + i^{(t)} \odot a^{(t)}<br>$$<br>其中，$\odot$为Hadamard积，在DNN中也用到过。</p><h4 id="2-4-LSTM之输出门"><a href="#2-4-LSTM之输出门" class="headerlink" title="2.4 LSTM之输出门"></a>2.4 LSTM之输出门</h4><p>有了新的隐藏细胞状态$C^{(t)}$，我们就可以来看输出门了，子结构如下：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fqfyqkrzkxj30ao06q0sm.jpg" alt=""></p><p>从图中可以看出，隐藏状态$h^{(t)}$的更新由两部分组成，第一部分是$o^{(t)}$, 它由上一序列的隐藏状态$h^{(t-1)}$和本序列数据$x^{(t)}$，以及激活函数sigmoid得到，第二部分由隐藏状态$C^{(t)}$和tanh激活函数组成, 即：<br>$$<br>o^{(t)} = \sigma(W_oh^{(t-1)} + U_ox^{(t)} + b_o)<br>$$<br>$$<br>h^{(t)} = o^{(t)} \odot tanh(C^{(t)})<br>$$<br>通过本节的剖析，相信大家对于LSTM的模型结构已经有了解了。当然，有些LSTM的结构和上面的LSTM图稍有不同，但是原理是完全一样的。</p><h3 id="3-LSTM重要分析"><a href="#3-LSTM重要分析" class="headerlink" title="3. LSTM重要分析"></a>3. LSTM重要分析</h3><p>让我们首先看一下RNN的拓扑图：<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fqo3905fv7j30k0083t97.jpg" alt="RNN拓扑结构"></p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fqfypi8975j30l0082mxc.jpg" alt=""></p><p>我们再来仔细观察这张图。<br>可以看到中间的 <strong>cell 里面有四个黄色小框</strong>，你如果理解了那个代表的含义一切就明白了，<strong>每一个小黄框代表一个前馈网络层</strong>，对，就是经典的神经网络的结构，<strong>num_units就是这个层的隐藏神经元个数</strong>，就这么简单。其中1、2、4的激活函数是 sigmoid，第三个的激活函数是 tanh。</p><p>另外几个需要注意的地方：<br>1、 <strong>cell 的状态是一个向量，是有多个值的</strong>。。。一开始没有理解这点的时候怎么都想不明白<br>2、 <strong>上一次的状态 h(t-1)是怎么和下一次的输入 x(t) 结合（concat）起来的</strong>，这也是很多资料没有明白讲的地方，也很简单，<strong>concat， 直白的说就是把二者直接拼起来</strong>，比如 x是28位的向量，h(t-1)是128位的，那么拼起来就是156位的向量，就是这么简单。。<br>3、 <strong>cell 的权重是共享的</strong>，这是什么意思呢？这是指这张图片上有三个绿色的大框，代表三个 cell 对吧，但是实际上，它<strong>只是代表了一个 cell 在不同时序时候的状态</strong>，所有的数据只会通过一个 cell，然后不断更新它的权重。<br>4、那么一层的 LSTM 的参数有多少个？根据第 3 点的说明，我们知道参数的数量是由 cell 的数量决定的，这里只有一个 cell，所以参数的数量就是这个 cell 里面用到的参数个数。假设 num_units 是128，输入是28位的，那么根据上面的第 2 点，可以得到，四个小黄框的参数一共有 （128+28）x（128 x 4），也就是156 x 512，可以看看 TensorFlow 的最简单的 LSTM 的案例，中间层的参数就是这样，不过还要加上输出的时候的激活函数的参数，假设是10个类的话，就是128*10的 W 参数和10个bias 参数<br>5、cell 最上面的一条线的状态即 s(t) 代表了长时记忆，而下面的 h(t)则代表了工作记忆或短时记忆。</p><p>我们来举个栗子🌰：<br><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fqnv62ctdhj30k00e53yz.jpg" alt=""></p><p>将一个28*28的mnist数据集图片按行送入RNN,从而实现手写体数字识别。上图这里按行切了28行（一般按列来做切片,_H为128 是因为RNN单元有128个LSTM Cell,所以需要一次线性转换）,使用tensorflow也能取得还算是不错的效果。不过tensorflow的CTC模块可以更好的处理变长验证码的识别。</p><pre><code>
def _RNN(_X,batch_size, _W, _b,num_layers,_nsteps):
    # 1.将输入从[batchsize, nsteps, diminput]变成[nsteps, batchsize, diminput]
    _X = tf.transpose(_X, [1, 0, 2])
    # 2.再次转换成[nsteps*batchsize, diminput]
    _X = tf.reshape(_X, [-1, diminput])
    # 3.从输入层进入隐层：一个线性变换
    _H = tf.matmul(_X, _W[&#39;hidden&#39;]) + _b[&#39;hidden&#39;]
    # 4.使用这种RNN输入方式，tensorflow的rnn定义稍微简单点
    _Hsplit = tf.split(0, _nsteps, _H)
    # 5.LSTM的最终输出 (_O) and 状态 (_S)
    #    Both _O and _S consist of &#39;batchsize&#39; elements
    with tf.variable_scope(_name):
        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(dimhidden, forget_bias=1.0)
        lstm_cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell]*num_layers, state_is_tuple=True)
        state = lstm_cell.zero_state(batch_size,dtype=tf.float32)
        _LSTM_O, _LSTM_S = tf.nn.rnn(lstm_cell, _Hsplit, initial_state=state)
</code></pre><p>对照下图，这里的batchsize(5) 就是一个batch的大小，nsteps(28)就是rnn的time step ,diminput(28)就是单个rnn单元输入的数据维度。很显然 nsteps x diminput(28 x 28) 就是单个mnist的数据维度。 上述代码的示意图：</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fqnv71pz2oj30fe09wdg5.jpg" alt=""></p><h3 id="4-LSTM前向传播算法"><a href="#4-LSTM前向传播算法" class="headerlink" title="4. LSTM前向传播算法"></a>4. LSTM前向传播算法</h3><p>现在我们来总结下LSTM前向传播算法。LSTM模型有两个隐藏状态$h^{(t)}, C^{(t)}$，模型参数几乎是RNN的4倍，因为现在多了$W_f, U_f, b_f, W_a, U_a, b_a, W_i, U_i, b_i, W_o, U_o, b_o$这些参数。</p><p>前向传播过程在每个序列索引位置的过程为：</p><p>1）更新遗忘门输出：<br>$$<br>f^{(t)} = \sigma(W_fh^{(t-1)} + U_fx^{(t)} + b_f)<br>$$<br>2）更新输入门两部分输出：<br>$$<br>i^{(t)} = \sigma(W_ih^{(t-1)} + U_ix^{(t)} + b_i)<br>$$<br>$$<br>a^{(t)} = tanh(W_ah^{(t-1)} + U_ax^{(t)} + b_a)<br>$$<br>3）更新细胞状态：<br>$$<br>C^{(t)} = C^{(t-1)} \odot f^{(t)} + i^{(t)} \odot a^{(t)}<br>$$<br>4）更新输出门输出：<br>$$<br>o^{(t)} = \sigma(W_oh^{(t-1)} + U_ox^{(t)} + b_o)<br>$$<br>$$<br>h^{(t)} = o^{(t)} \odot tanh(C^{(t)})<br>$$<br>5）更新当前序列索引预测输出：<br>$$<br>\hat{y}^{(t)} = \sigma(Vh^{(t)} + c)<br>$$</p><h3 id="5-LSTM反向传播算法推导关键点"><a href="#5-LSTM反向传播算法推导关键点" class="headerlink" title="5.  LSTM反向传播算法推导关键点"></a>5. LSTM反向传播算法推导关键点</h3><p>有了LSTM前向传播算法，推导反向传播算法就很容易了， 思路和RNN的反向传播算法思路一致，也是通过梯度下降法迭代更新我们所有的参数，关键点在于计算所有参数基于损失函数的偏导数。</p><p>在RNN中，为了反向传播误差，我们通过隐藏状态$h^{(t)}$的梯度$\delta^{(t)}$一步步向前传播。在LSTM这里也类似。只不过我们这里有两个隐藏状态$h^{(t)}和C^{(t)}$。这里我们定义两个$\delta$，即：<br>$$<br>\delta_h^{(t)} = \frac{\partial L}{\partial h^{(t)}}<br>$$<br>$$<br>\delta_C^{(t)} = \frac{\partial L}{\partial C^{(t)}}<br>$$<br>反向传播时只使用了$\delta_C^{(t)}$,变量$\delta_h^{(t)}$仅为帮助我们在某一层计算用，并没有参与反向传播，这里要注意。如下图所示：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fqfyqwijijj30kq0s0aao.jpg" alt=""></p><p>而在最后的序列索引位置$\tau$的$\delta_h^{(\tau)}$和 $\delta_C^{(\tau)}$ 为：<br>$$<br>\delta_h^{(\tau)} =\frac{\partial L}{\partial O^{(\tau)}} \frac{\partial O^{(\tau)}}{\partial h^{(\tau)}} = V^T(\hat{y}^{(\tau)} - y^{(\tau)})<br>$$<br>$$<br>\delta_C^{(\tau)} =\frac{\partial L}{\partial h^{(\tau)}} \frac{\partial h^{(\tau)}}{\partial C^{(\tau)}} = \delta_h^{(\tau)} \odot o^{(\tau)} \odot (1 - tanh^2(C^{(\tau)}))<br>$$<br>接着我们由$\delta_C^{(t+1)}$反向推导$\delta_C^{(t)}$。</p><p>$\delta_h^{(t)}$的梯度由本层的输出梯度误差决定，即：<br>$$<br> \delta_h^{(t)} =\frac{\partial L}{\partial h^{(t)}} = V^T(\hat{y}^{(t)} - y^{(t)})<br>$$<br>而$\delta_C^{(t)}$的反向梯度误差由前一层$\delta_C^{(t+1)}$的梯度误差和本层的从$h^{(t)}$传回来的梯度误差两部分组成，即：<br>$$<br>\delta_C^{(t)} =\frac{\partial L}{\partial C^{(t+1)}} \frac{\partial C^{(t+1)}}{\partial C^{(t)}} + \frac{\partial L}{\partial h^{(t)}}\frac{\partial h^{(t)}}{\partial C^{(t)}} = \delta_C^{(t+1)}\odot f^{(t+1)} + \delta_h^{(t)} \odot o^{(t)} \odot (1 - tanh^2(C^{(t)}))<br>$$<br>有了$\delta_h^{(t)}$和$\delta_C^{(t)}$， 计算这一大堆参数的梯度就很容易了，这里只给出WfWfW_f的梯度计算过程，其他的$U_f, b_f, W_a, U_a, b_a, W_i, U_i, b_i, W_o, U_o, b_o，V, c$的梯度大家只要照搬就可以了。<br>$$<br>\frac{\partial L}{\partial W_f} = \sum\limits_{t=1}^{\tau}\frac{\partial L}{\partial C^{(t)}} \frac{\partial C^{(t)}}{\partial f^{(t)}} \frac{\partial f^{(t)}}{\partial W_f} =\sum\limits_{t=1}^{\tau} \delta_C^{(t)} \odot C^{(t-1)} \odot f^{(t)}(1-f^{(t)}) (h^{(t-1)})^T<br>$$</p><h3 id="6-LSTM的正则化"><a href="#6-LSTM的正则化" class="headerlink" title="6. LSTM的正则化"></a>6. LSTM的正则化</h3><p>在rnn中使用dropout的方法和cnn不同，推荐大家去把<a href="https://arxiv.org/pdf/1409.2329.pdf" target="_blank" rel="noopener">recurrent neural network regularization</a>看一遍。<br>所谓dropout,就是指网络中每个单元在每次有数据流入时以一定的概率(keep prob)正常工作，否则输出0值。这是是一种有效的正则化方法，可以有效防止过拟合。<br>在rnn中进行dropout时，对于rnn的部分不进行dropout，也就是说从t-1时候的状态传递到t时刻进行计算时，这个中间不进行memory的dropout；仅在同一个t时刻中，<strong>多层cell之间</strong>传递信息的时候进行dropout，如下图所示:</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fqo356xp74j308706amwy.jpg" alt=""></p><p>具体在代码实现中可以使用tensorflow的DropoutWrapper api:</p><blockquote><p>tf.contrib.rnn.DropoutWrapper<br>Defined in tensorflow/python/ops/rnn_cell_impl.py.</p></blockquote><pre><code>__init__(
    cell,
    input_keep_prob=1.0,
    output_keep_prob=1.0,
    state_keep_prob=1.0,
    variational_recurrent=False,
    input_size=None,
    dtype=None,
    seed=None,
    dropout_state_filter_visitor=None
)
</code></pre><p>上图中，t-2时刻的输入$x_{t−2}$首先传入第一层cell，这个过程有dropout，但是从t−2时刻的第一层cell传到t−1,t,t+1的第一层cell这个中间都不进行dropout。再从t+1时候的第一层cell向同一时刻内后续的cell传递时，这之间又有dropout了。</p><p>在使用<code>tf.nn.rnn_cell.DropoutWrapper</code>时，同样有一些参数，例如<code>input_keep_prob,output_keep_prob</code>等，分别控制输入和输出的dropout概率，很好理解。<br>可以从官方文档中看到，它有input_keep_prob和output_keep_prob，也就是说裹上这个DropoutWrapper之后，如果我希望是input传入这个cell时dropout掉一部分input信息的话，就设置input_keep_prob，那么传入到cell的就是部分input；如果我希望这个cell的output只部分作为下一层cell的input的话，就定义output_keep_prob。<br>备注：<strong>Dropout只能是层与层之间</strong>（输入层与LSTM1层、LSTM1层与LSTM2层）的Dropout；同一个层里面，T时刻与T+1时刻是不会Dropout的。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h3 id="7-LSTM小结"><a href="#7-LSTM小结" class="headerlink" title="7. LSTM小结"></a>7. LSTM小结</h3><p>LSTM虽然结构复杂，但是只要理顺了里面的各个部分和之间的关系，进而理解前向反向传播算法是不难的。当然实际应用中LSTM的难点不在前向反向传播算法，这些有算法库帮你搞定，模型结构和一大堆参数的调参才是让人头痛的问题。不过，理解LSTM模型结构仍然是高效使用的前提。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>1） <a href="http://neuralnetworksanddeeplearning.com/index.html" target="_blank" rel="noopener">Neural Networks and Deep Learning</a> by By Michael Nielsen</p><p>2） <a href="http://www.deeplearningbook.org/" target="_blank" rel="noopener">Deep Learning</a>, book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</p><p>3） <a href="http://ufldl.stanford.edu/tutorial/" target="_blank" rel="noopener">UFLDL Tutorial</a></p><p>4）<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding-LSTMs</a></p><blockquote style="margin:2em 0 0;padding:.5em 1em;border-left:3px solid #f44336;background-color:#f5f5f5;list-style:none"><p> <strong>This blog is under a <a href="https://pancakeawesome.ink/" target="_blank">CC BY-NC-SA 3.0 Unported License</a></strong><br> <strong>本文链接：</strong><a href="http://pancakeawesome.ink/LSTM模型小结.html">http://pancakeawesome.ink/LSTM模型小结.html</a></p></blockquote></div><div id="changyan-comment"><div id="SOHUCS" sid="LSTM模型小结.html"></div><script type="text/javascript">!function(){var t="da223e602e0abf03eded8d4c19e7d862";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=cytdf2o7Q&conf='+t+'"><\/script>');else{!function(t,e){var n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,a=document.createElement("script");a.setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:"cytdf2o7Q",conf:t})})}}()</script></div><style>#changyan-comment{background-color:#eee;padding:2pc}</style></div><nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col"> <a href="/最优化方法总结.html" id="post_nav-newer" class="prev-content"><button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_back</i></button> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 新篇</a><div class="section-spacer"></div> <a href="/RNN循环神经网络小结.html" id="post_nav-older" class="next-content">旧篇 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_forward</i></button></a></nav></div></div><div class="sidebar-overlay"></div><aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation"><div id="sidebar-main"><div class="sidebar-header header-cover" style="background-image:url(/img/thumbnail/sidebar_header.jpg)"><div class="top-bar"></div> <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display:initial" data-upgraded=",MaterialButton,MaterialRipple"> <i class="material-icons">clear_all</i><span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></button><div class="sidebar-image"> <img src="/img/rip.jpeg" alt="Edward Guan's avatar"></div> <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">guanchao930908@163.com<b class="caret"></b></a></div><ul class="nav sidebar-nav"><li class="dropdown"><ul id="settings-dropdown" class="dropdown-menu"><li> <a href="mailto:guanchao930908@163.com" target="_blank" title="Email Me"><i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i> Email Me</a></li></ul></li><li id="sidebar-first-li"> <a href="/"><i class="material-icons sidebar-material-icons">home</i> 主页</a></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">timeline</i> 归档<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">9</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">11</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/02/">二月 2018<span class="sidebar_archives-count">16</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">13</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/10/">十月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">10</span></a></li></ul></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">chrome_reader_mode</i> 分类<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/categories/OCR/">OCR<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/blog/">blog<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/categories/javascript/">javascript<span class="sidebar_archives-count">12</span></a></li><li><a class="sidebar_archives-link" href="/categories/nodejs/">nodejs<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/react/">react<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端工具/">前端工具<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端技术/">前端技术<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据分析/">数据分析<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据可视化/">数据可视化<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/机器学习/">机器学习<span class="sidebar_archives-count">25</span></a></li><li><a class="sidebar_archives-link" href="/categories/深度学习/">深度学习<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/categories/目标检测/">目标检测<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/算法思想/">算法思想<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/计算机网络/">计算机网络<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/论文笔记/">论文笔记<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/categories/软件开发/">软件开发<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/面试/">面试<span class="sidebar_archives-count">1</span></a></li></ul></li><li> <a href="/tags" title="标签云"><i class="material-icons sidebar-material-icons">cloud_circle</i> 标签云</a></li><li class="divider"></li><li> <a href="/timeline" title="Timeline"><i class="material-icons sidebar-material-icons">send</i> Timeline</a></li><li> <a href="/gallery" title="Gallery"><i class="material-icons sidebar-material-icons">photo_library</i> Gallery</a></li><li> <a href="/aboutMe" title="About Me"><i class="material-icons sidebar-material-icons">person_pin</i> About Me</a></li><li class="divider"></li><li> <a href="/archives">文章总数 <span class="sidebar-badge">100</span></a></li></ul></div></aside><div id="back-to-top" class="toTop-wrap"> <a href="#top" class="toTop"><i class="material-icons footer_top-i">expand_less</i></a></div><footer class="mdl-mini-footer" id="bottom"><div class="mdl-mini-footer--left-section sns-list"> <a href="https://twitter.com/591153977" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-twitter"> <span class="visuallyhidden">Twitter</span></button></a> <a href="https://www.facebook.com/profile.php?id=100011433530812" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-facebook"> <span class="visuallyhidden">Facebook</span></button></a> <a href="https://www.instagram.com/edward930908/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-instagram"> <span class="visuallyhidden">Instagram</span></button></a> <a href="https://github.com/PancakeAwesome" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-github"> <span class="visuallyhidden">Github</span></button></a> <a href="https://www.linkedin.com/in/%E8%B6%85-%E7%AE%A1-89495a145/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-linkedin"> <span class="visuallyhidden">LinkedIn</span></button></a></div><div id="copyright"> Copyright&nbsp;©<script type="text/javascript">var fd=new Date;document.write("&nbsp;"+fd.getFullYear()+"&nbsp;")</script>Edward's Blog<br><p>Hosted by <a href="https://pages.coding.me" style="font-weight:700">Coding Pages</a></p></div><div class="mdl-mini-footer--right-section"><div><div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div><div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div></div></div></footer><script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==",!0)</script><script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==",!0)</script><script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==",!0)</script><script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><script id="cy_cmt_num" src="https://changyan.sohu.com/upload/plugins/plugins.list.count.js?clientId=cytdf2o7Q"></script><script>var agent=navigator.userAgent.toLowerCase();agent.indexOf("ucbrowser")>0&&(document.write('<link rel="stylesheet" href="/css/uc.css">'),alert("由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。"))</script><script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==",!0)</script><script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script><script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script><script>!function(){for(var e=document.querySelectorAll('script[type="text/ls-javascript"]'),r=0;r<e.length;++r){var o=e[r];lsloader.runInlineScript(o.id,o.id)}}(),console.log("\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;")</script></main></div><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>