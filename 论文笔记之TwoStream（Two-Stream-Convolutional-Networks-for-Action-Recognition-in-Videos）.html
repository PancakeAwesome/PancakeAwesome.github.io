<!DOCTYPE html><html style="display:none" lang="zh"><head><meta charset="utf-8"><script>window.materialVersion="1.5.0",window.oldVersion=["codestartv1","1.3.4","1.4.0","1.4.0b1"]</script><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://busuanzi.ibruce.info"><link rel="dns-prefetch" href="https://changyan.sohu.com"><title> 论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos） | Edward&#39;s Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0097A7"><meta name="author" content="Edward Guan"><meta name="description" itemprop="description" content="Two-Stream Convolutional Networks for Action Recognition in Videos"><meta name="keywords" content="前端,node,react,js,java,自学编程,学习分享,UESTC,深度学习,论文笔记,video analysis"><script>window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}},lsloader.removeLS=function(e){try{localStorage.removeItem(e)}catch(e){}},lsloader.setLS=function(e,t){try{localStorage.setItem(e,t)}catch(e){}},lsloader.getLS=function(e){var t="";try{t=localStorage.getItem(e)}catch(e){t=""}return t},versionString="/*"+(window.materialVersion||"unknownVersion")+"*/",lsloader.clean=function(){try{for(var e=[],t=0;t<localStorage.length;t++)e.push(localStorage.key(t));e.forEach(function(e){var t=lsloader.getLS(e);window.oldVersion&&window.oldVersion.reduce(function(e,n){return e||-1!==t.indexOf("/*"+n+"*/")},!1)&&lsloader.removeLS(e)})}catch(e){}},lsloader.clean(),lsloader.load=function(e,t,n,s){"boolean"==typeof n&&(s=n,n=void 0),s=s||!1,n=n||function(){};var a;if((a=this.getLS(e))&&-1===a.indexOf(versionString))return this.removeLS(e),void this.requestResource(e,t,n,s);if(a){if(a.split(versionString)[0]!=t)return console.log("reload:"+t),this.removeLS(e),void this.requestResource(e,t,n,s);a=a.split(versionString)[1],s?(this.jsRunSequence.push({name:e,code:a}),this.runjs(t,e,a)):(document.getElementById(e).appendChild(document.createTextNode(a)),n())}else this.requestResource(e,t,n,s)},lsloader.requestResource=function(e,t,n,s){var a=this;s?this.iojs(t,e,function(e,t,n){a.setLS(t,e+versionString+n),a.runjs(e,t,n)}):this.iocss(t,e,function(n){document.getElementById(e).appendChild(document.createTextNode(n)),a.setLS(e,t+versionString+n)},n)},lsloader.iojs=function(e,t,n){var s=this;s.jsRunSequence.push({name:t,code:""});try{var a=new XMLHttpRequest;a.open("get",e,!0),a.onreadystatechange=function(){if(4==a.readyState){if((a.status>=200&&a.status<300||304==a.status)&&""!=a.response)return void n(e,t,a.response);s.jsfallback(e,t)}},a.send(null)}catch(n){s.jsfallback(e,t)}},lsloader.iocss=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.iofonts=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.runjs=function(e,t,n){if(t&&n)for(var s in this.jsRunSequence)this.jsRunSequence[s].name==t&&(this.jsRunSequence[s].code=n);if(this.jsRunSequence[0]&&this.jsRunSequence[0].code&&"failed"!=this.jsRunSequence[0].status)(o=document.createElement("script")).appendChild(document.createTextNode(this.jsRunSequence[0].code)),o.type="text/javascript",document.getElementsByTagName("head")[0].appendChild(o),this.jsRunSequence.shift(),this.jsRunSequence.length>0&&this.runjs();else if(this.jsRunSequence[0]&&"failed"==this.jsRunSequence[0].status){var a=this,o=document.createElement("script");o.src=this.jsRunSequence[0].path,o.type="text/javascript",this.jsRunSequence[0].status="loading",o.onload=function(){a.jsRunSequence.shift(),a.jsRunSequence.length>0&&a.runjs()},document.body.appendChild(o)}},lsloader.tagLoad=function(e,t){this.jsRunSequence.push({name:t,code:"",path:e,status:"failed"}),this.runjs()},lsloader.jsfallback=function(e,t){if(!this.jsnamemap[t]){this.jsnamemap[t]=t;for(var n in this.jsRunSequence)this.jsRunSequence[n].name==t&&(this.jsRunSequence[n].code="",this.jsRunSequence[n].status="failed",this.jsRunSequence[n].path=e);this.runjs()}},lsloader.cssfallback=function(e,t,n){if(!this.cssnamemap[t]){this.cssnamemap[t]=1;var s=document.createElement("link");s.type="text/css",s.href=e,s.rel="stylesheet",s.onload=s.onerror=n;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(s,a)}},lsloader.runInlineScript=function(e,t){var n=document.getElementById(t).innerText;this.jsRunSequence.push({name:e,code:n}),this.runjs()},lsloader.loadCombo=function(e){var t="",n={};for(var s in e){var a=this.getLS(e[s].name);if(a)var o=a.split(versionString)[0],i=a.split(versionString)[1];else o="";o==e[s].path?this.jsRunSequence.push({name:e[s].name,code:i,path:e[s].path}):(this.jsRunSequence.push({name:e[s].name,code:null,path:e[s].path,status:"comboloading"}),n[e[s].name]=!0,t+=(""==t?"":";")+e[s].path)}var u=this;if(t){var r=new XMLHttpRequest;r.open("get",combo+t,!0),r.onreadystatechange=function(){if(4==r.readyState)if(r.status>=200&&r.status<300||304==r.status){if(""!=r.response)return void u.runCombo(r.response,n)}else{for(var e in u.jsRunSequence)n[u.jsRunSequence[e].name]&&(u.jsRunSequence[e].status="failed");u.runjs()}},r.send(null)}this.runjs()},lsloader.runCombo=function(e,t){(e=e.split("/*combojs*/")).shift();for(var n in this.jsRunSequence)t[this.jsRunSequence[n].name]&&e[0]&&(this.jsRunSequence[n].status="comboJS",this.jsRunSequence[n].code=e[0],this.setLS(this.jsRunSequence[n].name,this.jsRunSequence[n].path+versionString+e[0]),e.shift());this.runjs()}</script><script>function Queue(){this.dataStore=[],this.offer=function(e){this.debug&&console.log("Offered a Queued Function."),"function"==typeof e?this.dataStore.push(e):console.log("You must offer a function.")},this.poll=function(){return this.debug&&console.log("Polled a Queued Function."),this.dataStore.shift()},this.execNext=function(){var e=this.poll();void 0!==e&&(this.debug&&console.log("Run a Queued Function."),e())},this.debug=!1,this.startDebug=function(){this.debug=!0}}var queue=new Queue</script><link rel="icon shortcut" type="image/ico" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="icon" sizes="192x192" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="apple-touch-icon" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="apple-mobile-web-app-title" content="Title"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="480"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="apple-mobile-web-app-title" content="Edward&#39;s Blog"> <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie-blocker.css"><script src="/js/ie-blocker.zhCN.js"></script><![endif]--><style id="material_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="style_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_theme"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_theme","/css/prettify/github-v2.min.css?AfzKxt++K+/lhZBlSjnxwg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style>body,html{font-family:Roboto,"Helvetica Neue",Helvetica,"PingFang SC","Hiragino Sans GB","Microsoft YaHei","微软雅黑",Arial,sans-serif;overflow-x:hidden!important}code{font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace}a{color:#00838f}#scheme-Paradox .hot_tags-count,#scheme-Paradox .sidebar-colored .sidebar-badge,#scheme-Paradox .sidebar-colored .sidebar-header,#scheme-Paradox .sidebar_archives-count,#search-form-label:after,#search-label,.mdl-card__media{background-color:#0097a7!important}#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus,#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover{color:#0097a7!important}#ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a,#post_entry-right-info,.sidebar-colored .sidebar-nav li:hover>a,.sidebar-colored .sidebar-nav li:hover>a i,.sidebar-colored .sidebar-nav li>a:focus i,.sidebar-colored .sidebar-nav li>a:hover,.sidebar-colored .sidebar-nav li>a:hover i,.sidebar-colored .sidebar-nav>.open>a,.sidebar-colored .sidebar-nav>.open>a:focus,.sidebar-colored .sidebar-nav>.open>a:hover{color:#0097a7!important}.toTop{background:#757575!important}.material-layout .material-index>.material-nav,.material-layout .material-post>.material-nav,.material-nav a{color:#757575}#scheme-Paradox .MD-burger-layer{background-color:#757575}#scheme-Paradox #post-toc-trigger-btn{color:#757575}.post-toc a:hover{color:#00838f;text-decoration:underline}</style><style>body{background-color:#f5f5f5}#scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{background-color:#fff}</style><style>.fade{transition:all .8s linear;-webkit-transform:translate3d(0,0,0);-moz-transform:translate3d(0,0,0);-ms-transform:translate3d(0,0,0);-o-transform:translate3d(0,0,0);transform:translate3d(0,0,0);opacity:1}.fade.out{opacity:0}</style><link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet"><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"><script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==",!0)</script><meta property="og:url" content="http://pancakeawesome.ink"><meta property="og:type" content="blog"><meta property="og:title" content="论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos） | Edward&#39;s Blog"><meta property="og:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta property="og:description" content="Two-Stream Convolutional Networks for Action Recognition in Videos"><meta property="og:article:tag" content="深度学习"><meta property="og:article:tag" content="论文笔记"><meta property="og:article:tag" content="video analysis"><meta property="article:published_time" content="Tue Jun 12 2018 15:03:03 GMT+0800"><meta property="article:modified_time" content="Tue Jun 12 2018 15:08:03 GMT+0800"><meta name="twitter:title" content="论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos） | Edward&#39;s Blog"><meta name="twitter:description" content="Two-Stream Convolutional Networks for Action Recognition in Videos"><meta name="twitter:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="http://pancakeawesome.ink"><link rel="canonical" href="http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html"><script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html",
    "headline": "论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos）",
    "datePublished": "Tue Jun 12 2018 15:03:03 GMT+0800",
    "dateModified": "Tue Jun 12 2018 15:08:03 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Edward Guan",
        "image": {
            "@type": "ImageObject",
            "url": "/img/rip.jpeg"
        },
        "description": "你说人生艳丽我没有异议，你说人生忧郁我不言语"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Edward&#39;s Blog",
        "logo": {
            "@type":"ImageObject",
            "url": "http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"
        }
    },
    "keywords": ",深度学习,论文笔记,video analysis前端,node,react,js,java,自学编程,学习分享,UESTC",
    "description": "Two-Stream Convolutional Networks for Action Recognition in Videos",
}
</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0c041dca6f79c4e40fb45d1283e327e7";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body id="scheme-Paradox" class="lazy"><div class="material-layout mdl-js-layout has-drawer is-upgraded"><main class="material-layout__content" id="main"><div id="top"></div> <button class="MD-burger-icon sidebar-toggle"><span class="MD-burger-layer"></span></button> <button id="post-toc-trigger-btn" class="mdl-button mdl-js-button mdl-button--icon"> <i class="material-icons">format_list_numbered</i></button><ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh;overflow-y:scroll"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#前言"><span class="post-toc-number">1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#细节"><span class="post-toc-number">2.</span> <span class="post-toc-text">细节</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#optical-flow-stacking"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">optical flow stacking</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#trajectory-stacking"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">trajectory stacking</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#multi-task"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">multi-task</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#后记"><span class="post-toc-number">3.</span> <span class="post-toc-text">后记</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#实验结果："><span class="post-toc-number">3.1.</span> <span class="post-toc-text">实验结果：</span></a></li></ol></li></ol></ul><div class="material-post_container"><div class="material-post mdl-grid"><div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col"><div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50"><script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 30 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script><p class="article-headline-p"> 论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos）</p></div><div class="mdl-color-text--grey-700 mdl-card__supporting-text meta"><div id="author-avatar"> <img src="/img/rip.jpeg" width="44px" height="44px" alt="Author Avatar"></div><div> <strong>Edward Guan</strong> <span>6月 12, 2018</span></div><div class="section-spacer"></div> <button id="article-functions-qrcode-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">devices other</i> <span class="visuallyhidden">devices other</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-qrcode-button"><li class="mdl-menu__item">在其它设备中阅读本文章</li> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAEyUlEQVR42u3ay24cMQwEwP3/n06uAYKd7SYl2IZLJ8OPGalkYKmmXn+MxXghwIcPHz4DHz58+Ax8+H4I3yse///+uye8e/6/30n+dvacD4t/fPvz2vHhw4cPH75TfPkr8799XtJmGcl7n5+8WTs+fPjw4cN3iq99TVLEtE/Li6G2fJmVUPjw4cOHD9/X8iWL2W/AJlxIoPHhw4cPH76fxZeHCC1iO+4F9/jw4cOHD99tvvbjvy1x9of8ZJ6bzb7e68CHDx8+fPjWJcJP//oL7vfhw4cPH75fzNeOvNTYXzhro4HnwOLUwIcPHz58+DZ8m+tis4trG+i8PXDqXcPEBR8+fPjw4XssXPKJtsH3M30y6f2y28b5h5Xiw4cPHz58C768yJi1xttl7AuafKsO9zrw4cOHDx++mG8GkRzd8w3YFyWzGdbbgw8fPnz48B3la7/TRv85wWypz+ibLcGHDx8+fPj2fJsLaqeO7u2Fs00ZlK+l6HXgw4cPHz58Jd+sfGkP5LPfTIqhs3P70E7Ahw8fPnz41nzPH9X5FJOpnwoC8phg307Ahw8fPnz4TvG1l7fyyeXLPhXZb0qTZC348OHDhw/fKb6kBJkd1zfh+KYcmTX7n+ePDx8+fPjw3eBr2+GbEmT/nJy7fSM+fPjw4cN3my+ZYjLaC2Qz0JZ71nTHhw8fPnz4bvCdOoS3pcks6N8c/mdtCXz48OHDh+8U3yxMb0uH9hJ2fnGtbRLkJQ4+fPjw4cN3jy/5IG8P+cmlsRlTu/h8dfjw4cOHD9/X8m1oNnHDLHyfzTxvkOPDhw8fPnxn+fKwYHOkz3/abkbbAm+b9Pjw4cOHD98pvvZxbTh+qtTYxASbIgkfPnz48OE7y/daj2RL2vZ8sgH7gD6/EIAPHz58+PDt+fJDeHt0z4/xs0P+PsLIV4cPHz58+PDd45tdU5sFAbPnt0VP2zwownp8+PDhw4dv0SbPm9azBbfxQd7Cn7XShzPEhw8fPnz4rvHlD20bz3kQkF+kywOIttDBhw8fPnz4TvHdCNPzxbdYs7m1/xB1mxwfPnz48OFb3LDaHNTbjcmvuM3ihlkpdrFNjg8fPnz4fj3f7LB9KiifFT3tNuSbPQzr8eHDhw8fvpivLS82C5h93cbu+7kdDuvx4cOHDx++4Di9aWzP6Dct9jbQnzUJ8OHDhw8fvtt8CUcL1IbpebDeUs4uwOHDhw8fPnyn+NpLY3mJkAfo+VbNGvazsgwfPnz48OE7xZd8tM+w2sW3v9Ny5I3w+pYBPnz48OHDN+JrX5AUPfnG5NH/LEq4Etbjw4cPHz58oz7v4Stc8U/z6D+PFU698e3T8OHDhw8fvgXfLGTP44MN9z6an73rw2bgw4cPHz58C75XPPIiIIdu/6otcdoAImoD4MOHDx8+fGu+vFjJj+6zSW+KnllDvW024MOHDx8+fKf4ZiVIUjTMQvN824omd3klLooM8OHDhw8fvmt8Lei+1T0LCGZt/mFYjw8fPnz48F3mS16ZlyNtU7wtO2brertefPjw4cOH7xBfe6mrbYfnG5Cj5Ft46lIdPnz48OHDt+ebNblvRPn7qH0GWjwZHz58+PDhW/AZq8jAwIcPHz4DHz58+Ax8+L7X+AsfsZZUXuYo6QAAAABJRU5ErkJggg=="></ul> <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">bookmark</i> <span class="visuallyhidden">bookmark</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button"><li class="mdl-menu__item"> <a class="post_tag-link" href="/tags/video-analysis/">video analysis</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/深度学习/">深度学习</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/论文笔记/">论文笔记</a></li></ul> <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">share</i> <span class="visuallyhidden">share</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button"><a class="post_share-link" href="#"><li class="mdl-menu__item"><span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span> &nbsp;浏览量</span></li></a><a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos）&url=http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html&pic=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&searchPic=false&style=simple" target="_blank"><li class="mdl-menu__item"> 分享到微博</li></a><a class="post_share-link" href="https://twitter.com/intent/tweet?text=论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos）&url=http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html&via=Edward Guan" target="_blank"><li class="mdl-menu__item"> 分享到 Twitter</li></a><a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html" target="_blank"><li class="mdl-menu__item"> 分享到 Facebook</li></a><a class="post_share-link" href="https://plus.google.com/share?url=http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html" target="_blank"><li class="mdl-menu__item"> 分享到 Google+</li></a><a class="post_share-link" href="https://www.linkedin.com/shareArticle?mini=true&url=http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html&title=论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos）" target="_blank"><li class="mdl-menu__item"> 分享到 LinkedIn</li></a><a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Edward&#39;s Blog&title=论文笔记之TwoStream（Two-Stream Convolutional Networks for Action Recognition in Videos）&summary=技术分享,学习笔记&pics=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&url=http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html" target="_blank"><li class="mdl-menu__item"> 分享到 QQ</li></a></ul></div><div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>论文：Two-Stream Convolutional Networks for Action Recognition in Videos<br>链接：<a href="https://arxiv.org/abs/1406.2199" target="_blank" rel="noopener">https://arxiv.org/abs/1406.2199</a><br>这篇文章是NIPS 2014年提出一个two stream网络来做video action的分类，比较经典。two stream表示两个并行的网络：spatial stream convnet 和 temporal stream convnet. 这两个并行网络的作用是：The spatial stream performs action recognition from still video frames, whilst the temporal stream is trained to recognise action from motion in the form of dense optical flow.</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><p>Figure1是two stream convnet的示意图。其中spatial stream convnet网络的输入是静态图像，该网络是一个分类网络，用来识别行为。temporal stream convnet输入是multi-frame optical flow，optical flow是从video中提取的特征信息。作者在总结中提到对于temporal stream convnet，用optical flow（翻译过来是光流信息）作为输入的效果要远远优于用raw stacked frame（就是简单的一系列帧）作为输入。<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fs8ehw59yfj30ho06dt99.jpg" alt=""><br>可以看出optical flow是文章的关键词，那么什么是optical flow？可以看原文的一段解释如下截图。<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fs8eixn01jj30ho0240sq.jpg" alt=""><br>所以optical flow是由一些displacement vector fields（每个vector用dt表示）组成的，其中dt是一个向量，表示第t帧的displacement vector，是通过第t和第t+1帧图像得到的。dt包含水平部分dtx和竖直部分dty，可以看Figure2中的（d）和（e）。因此如果一个video有L+1帧，那么一共可以得到2L个channel的optical flow，然后才能作为Figure1中temporal stream convnet网络的输入。</p><blockquote><p>FIugre2中的（a）和（b）表示连续的两帧图像，（c）表示一个optical flow，（d）和（e）分别表示一个displacement vector field的水平和竖直两部分。</p></blockquote><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fs8ej84okej30hz067q3n.jpg" alt=""><br>所以如果假设一个video的宽和高分别是w和h，那么Figure1中temporal stream convnet的输入维度应该是下面这样的。It代表整个vedio的输入（随机抽取的帧序列）<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fs8ejwgrivj302y00ujr5.jpg" alt=""><br>那么怎么得到Iτ？文章主要介绍了两种Iτ的计算方式，分别命名为optical flow stacking和trajectory stacking，这二者都可以作为前面temporal stream convnet网络的输入，接下来依次介绍。</p><h3 id="optical-flow-stacking"><a href="#optical-flow-stacking" class="headerlink" title="optical flow stacking"></a>optical flow stacking</h3><p>式子1列出了分别得到水平和竖直方向的Iτ的计算公式，其中（u，v）表示任意一个点的坐标。因此 Iτ(u,v,c) 存的就是(u,v)这个位置的displacement vector。原文：For an arbitrary point (u,v), the channels Iτ(u,v,c); c = [1; 2L] encode the motion at that point over a sequence of L frames。如Figure3的左图所示。<br><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fs8ek5842cj30cj01r743.jpg" alt=""></p><h3 id="trajectory-stacking"><a href="#trajectory-stacking" class="headerlink" title="trajectory stacking"></a>trajectory stacking</h3><p>式子2是关于如何得到Iτ，其中Pk表示k-th point along the trajectory。因此 Iτ(u,v,c) 存的就是vectors sampled at the locations Pk along the trajectory。如Figure3的右图所示。<br><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fs8ekvhwxej30i303rglk.jpg" alt=""></p><blockquote><p>Figure3分别介绍了optical flow stacking和trajectory stacking。实验证明optical flow stacking优于trajectory stacking。</p></blockquote><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fs8elbhe1gj30hy06ygm0.jpg" alt=""></p><blockquote><p>Optical flow stacking 方法存储的是位置(u,v)的位移矢量；<br>trajectory stacking方法存储的是在顺着轨迹线位于位置的向量。</p></blockquote><h3 id="multi-task"><a href="#multi-task" class="headerlink" title="multi-task"></a>multi-task</h3><p>spatial stream convnet因为输入是静态的图像，因此其预训练模型容易得到（一般采用在ImageNet数据集上的预训练模型），但是temporal stream convnet的预训练模型就需要在视频数据集上训练得到，但是目前能用的视频数据集规模还比较小（主要指的是UCF-101和HMDB-51这两个数据集，训练集数量分别是9.5K和3.7K个video）。因此作者采用multi-task的方式来解决。怎么做呢？首先原来的网络（temporal stream convnet）在全连接层后只有一个softmax层，现在要变成两个softmax层，一个用来计算HDMB-51数据集的分类输出，另一个用来计算UCF-101数据集的分类输出，这就是两个task。这两条支路有各自的loss，最后回传loss的时候采用的是两条支路loss的和。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h3 id="实验结果："><a href="#实验结果：" class="headerlink" title="实验结果："></a>实验结果：</h3><p>Table1是两个网络的实验结果，数据集都是UCF-101，该数据集包含13K的videos，平均每个video包含180帧图像，有101个action class。另外multi-task有用到HMDB-51数据集，其包含6.8K的video，有51个action class。<br>（a）是spatial stream convnet，主要对比了从头开始训练（from scratch）和在预训练模型上做fine tune的差别（pre-trained+fine tuning表示用预训练网络的参数初始化所有层，然后对所有层fine tune；pre-trained+last layer同样是用预训练网络的参数初始化所有层，但是只对最后一层fine tune，也就是前面那些层的参数在初始化后固定不变）。从实验结果可以看出直接在UCF-101数据集上从头开始训练容易过拟合。在后面的实验中作者采用第三种做法，也就是在预训练模型的基础上只fine tune最后一层的参数。<br>（b）表示temporal stream convnet的几种不同类型输入的差别，训练都是从头开始（from scratch）。其中optical flow stacking和trajectory stacking在前面都介绍过了，注意L参数对结果的影响，第一行中L=1相当于只给了一帧图像，另外在后面的实验中作者采用L=10。可以看出optical flow stacking的效果要优于trajectory stacking。最后一行的bi-dir表示bi-directional optical flow，感兴趣的可以看原文。<br>通过对比（a）和（b）可以看出temporal stream convnet的效果要优于spatial stream convnet，这说明对于action recognition而言，motion information的重要性。<br>另外，文中的一句话写得很好：This shows that while multi-frame information is important, it is also important to present it to a ConvNet in an appropriate manner. 翻译过来就是：都知道是那个理，就看你怎么实现了。哈哈<br><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fs8elubfhkj30i004vaa7.jpg" alt=""><br>Table2是multi task的实验结果。主要的修改内容包括：(i) fine-tuning a temporal network pre-trained on UCF-101; (ii) adding 78 classes from UCF-101, which are manually selected so that there is no intersection between these classes and the native HMDB-51 classes; (iii) using the multi-task formulation to learn a video representation, shared between the UCF-101 and<br>HMDB-51 classification tasks. Table2中的实验正是对比这几个修改的效果。<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fs8emg663wj30h903f0sr.jpg" alt=""><br>Table3是two-stream convnet的不同构建方式的实验结果对比。几个结论：(i) temporal and spatial recognition streams are complementary, as their fusion significantly improves on both (6% over temporal and 14% over spatial nets); (ii) SVM-based fusion of softmax scores outperforms fusion by averaging; (iii) using bi-directional flow is not beneficial in the case of ConvNet fusion; (iv) temporal ConvNet, trained using multi-task learning, performs the best both alone and when fused with a spatial net.<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fs8emon94bj30fc03ogll.jpg" alt=""><br>Table4是two stream convnet和其他算法的对比。<br><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fs8enkth9kj30h905z3yq.jpg" alt=""></p><blockquote style="margin:2em 0 0;padding:.5em 1em;border-left:3px solid #f44336;background-color:#f5f5f5;list-style:none"><p> <strong>This blog is under a <a href="https://pancakeawesome.ink/" target="_blank">CC BY-NC-SA 3.0 Unported License</a></strong><br> <strong>本文链接：</strong><a href="http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html">http://pancakeawesome.ink/论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html</a></p></blockquote></div><div id="changyan-comment"><div id="SOHUCS" sid="论文笔记之TwoStream（Two-Stream-Convolutional-Networks-for-Action-Recognition-in-Videos）.html"></div><script type="text/javascript">!function(){var t="da223e602e0abf03eded8d4c19e7d862";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=cytdf2o7Q&conf='+t+'"><\/script>');else{!function(t,e){var n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,a=document.createElement("script");a.setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:"cytdf2o7Q",conf:t})})}}()</script></div><style>#changyan-comment{background-color:#eee;padding:2pc}</style></div><nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col"><div class="section-spacer"></div> <a href="/论文笔记之TDDs（Action-Recognition-with-Trajectory-Pooled-Deep-Convolutional-Descriptors）.html" id="post_nav-older" class="next-content">旧篇 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_forward</i></button></a></nav></div></div><div class="sidebar-overlay"></div><aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation"><div id="sidebar-main"><div class="sidebar-header header-cover" style="background-image:url(/img/thumbnail/sidebar_header.jpg)"><div class="top-bar"></div> <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display:initial" data-upgraded=",MaterialButton,MaterialRipple"> <i class="material-icons">clear_all</i><span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></button><div class="sidebar-image"> <img src="/img/rip.jpeg" alt="Edward Guan's avatar"></div> <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">guanchao930908@163.com<b class="caret"></b></a></div><ul class="nav sidebar-nav"><li class="dropdown"><ul id="settings-dropdown" class="dropdown-menu"><li> <a href="mailto:guanchao930908@163.com" target="_blank" title="Email Me"><i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i> Email Me</a></li></ul></li><li id="sidebar-first-li"> <a href="/"><i class="material-icons sidebar-material-icons">home</i> 主页</a></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">timeline</i> 归档<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">11</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/02/">二月 2018<span class="sidebar_archives-count">16</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">13</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/10/">十月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">10</span></a></li></ul></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">chrome_reader_mode</i> 分类<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/categories/OCR/">OCR<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/blog/">blog<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/categories/javascript/">javascript<span class="sidebar_archives-count">12</span></a></li><li><a class="sidebar_archives-link" href="/categories/nodejs/">nodejs<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/react/">react<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端工具/">前端工具<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端技术/">前端技术<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据分析/">数据分析<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据可视化/">数据可视化<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/机器学习/">机器学习<span class="sidebar_archives-count">18</span></a></li><li><a class="sidebar_archives-link" href="/categories/深度学习/">深度学习<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/categories/目标检测/">目标检测<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/算法思想/">算法思想<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/计算机网络/">计算机网络<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/论文笔记/">论文笔记<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/categories/软件开发/">软件开发<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/面试/">面试<span class="sidebar_archives-count">1</span></a></li></ul></li><li> <a href="/tags" title="标签云"><i class="material-icons sidebar-material-icons">cloud_circle</i> 标签云</a></li><li class="divider"></li><li> <a href="/timeline" title="Timeline"><i class="material-icons sidebar-material-icons">send</i> Timeline</a></li><li> <a href="/gallery" title="Gallery"><i class="material-icons sidebar-material-icons">photo_library</i> Gallery</a></li><li> <a href="/aboutMe" title="About Me"><i class="material-icons sidebar-material-icons">person_pin</i> About Me</a></li><li class="divider"></li><li> <a href="/archives">文章总数 <span class="sidebar-badge">93</span></a></li></ul></div></aside><div id="back-to-top" class="toTop-wrap"> <a href="#top" class="toTop"><i class="material-icons footer_top-i">expand_less</i></a></div><footer class="mdl-mini-footer" id="bottom"><div class="mdl-mini-footer--left-section sns-list"> <a href="https://twitter.com/591153977" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-twitter"> <span class="visuallyhidden">Twitter</span></button></a> <a href="https://www.facebook.com/profile.php?id=100011433530812" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-facebook"> <span class="visuallyhidden">Facebook</span></button></a> <a href="https://www.instagram.com/edward930908/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-instagram"> <span class="visuallyhidden">Instagram</span></button></a> <a href="https://github.com/PancakeAwesome" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-github"> <span class="visuallyhidden">Github</span></button></a> <a href="https://www.linkedin.com/in/%E8%B6%85-%E7%AE%A1-89495a145/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-linkedin"> <span class="visuallyhidden">LinkedIn</span></button></a></div><div id="copyright"> Copyright&nbsp;©<script type="text/javascript">var fd=new Date;document.write("&nbsp;"+fd.getFullYear()+"&nbsp;")</script>Edward's Blog<br><p>Hosted by <a href="https://pages.coding.me" style="font-weight:700">Coding Pages</a></p></div><div class="mdl-mini-footer--right-section"><div><div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div><div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div></div></div></footer><script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==",!0)</script><script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==",!0)</script><script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==",!0)</script><script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><script id="cy_cmt_num" src="https://changyan.sohu.com/upload/plugins/plugins.list.count.js?clientId=cytdf2o7Q"></script><script>var agent=navigator.userAgent.toLowerCase();agent.indexOf("ucbrowser")>0&&(document.write('<link rel="stylesheet" href="/css/uc.css">'),alert("由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。"))</script><script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==",!0)</script><script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script><script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script><script>!function(){for(var e=document.querySelectorAll('script[type="text/ls-javascript"]'),r=0;r<e.length;++r){var o=e[r];lsloader.runInlineScript(o.id,o.id)}}(),console.log("\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;")</script></main></div><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>