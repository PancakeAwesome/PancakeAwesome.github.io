<!DOCTYPE html><html style="display:none" lang="zh"><head><meta charset="utf-8"><script>window.materialVersion="1.5.0",window.oldVersion=["codestartv1","1.3.4","1.4.0","1.4.0b1"]</script><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://busuanzi.ibruce.info"><link rel="dns-prefetch" href="https://changyan.sohu.com"><title> 集成学习之Adaboost算法原理小结 | Edward&#39;s Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0097A7"><meta name="author" content="Edward Guan"><meta name="description" itemprop="description" content="集成学习之Adaboost算法原理小结"><meta name="keywords" content="前端,node,react,js,java,自学编程,学习分享,UESTC,机器学习"><script>window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}},lsloader.removeLS=function(e){try{localStorage.removeItem(e)}catch(e){}},lsloader.setLS=function(e,t){try{localStorage.setItem(e,t)}catch(e){}},lsloader.getLS=function(e){var t="";try{t=localStorage.getItem(e)}catch(e){t=""}return t},versionString="/*"+(window.materialVersion||"unknownVersion")+"*/",lsloader.clean=function(){try{for(var e=[],t=0;t<localStorage.length;t++)e.push(localStorage.key(t));e.forEach(function(e){var t=lsloader.getLS(e);window.oldVersion&&window.oldVersion.reduce(function(e,n){return e||-1!==t.indexOf("/*"+n+"*/")},!1)&&lsloader.removeLS(e)})}catch(e){}},lsloader.clean(),lsloader.load=function(e,t,n,s){"boolean"==typeof n&&(s=n,n=void 0),s=s||!1,n=n||function(){};var a;if((a=this.getLS(e))&&-1===a.indexOf(versionString))return this.removeLS(e),void this.requestResource(e,t,n,s);if(a){if(a.split(versionString)[0]!=t)return console.log("reload:"+t),this.removeLS(e),void this.requestResource(e,t,n,s);a=a.split(versionString)[1],s?(this.jsRunSequence.push({name:e,code:a}),this.runjs(t,e,a)):(document.getElementById(e).appendChild(document.createTextNode(a)),n())}else this.requestResource(e,t,n,s)},lsloader.requestResource=function(e,t,n,s){var a=this;s?this.iojs(t,e,function(e,t,n){a.setLS(t,e+versionString+n),a.runjs(e,t,n)}):this.iocss(t,e,function(n){document.getElementById(e).appendChild(document.createTextNode(n)),a.setLS(e,t+versionString+n)},n)},lsloader.iojs=function(e,t,n){var s=this;s.jsRunSequence.push({name:t,code:""});try{var a=new XMLHttpRequest;a.open("get",e,!0),a.onreadystatechange=function(){if(4==a.readyState){if((a.status>=200&&a.status<300||304==a.status)&&""!=a.response)return void n(e,t,a.response);s.jsfallback(e,t)}},a.send(null)}catch(n){s.jsfallback(e,t)}},lsloader.iocss=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.iofonts=function(e,t,n,s){var a=this;try{var o=new XMLHttpRequest;o.open("get",e,!0),o.onreadystatechange=function(){if(4==o.readyState){if((o.status>=200&&o.status<300||304==o.status)&&""!=o.response)return n(o.response),void s();a.cssfallback(e,t,s)}},o.send(null)}catch(n){a.cssfallback(e,t,s)}},lsloader.runjs=function(e,t,n){if(t&&n)for(var s in this.jsRunSequence)this.jsRunSequence[s].name==t&&(this.jsRunSequence[s].code=n);if(this.jsRunSequence[0]&&this.jsRunSequence[0].code&&"failed"!=this.jsRunSequence[0].status)(o=document.createElement("script")).appendChild(document.createTextNode(this.jsRunSequence[0].code)),o.type="text/javascript",document.getElementsByTagName("head")[0].appendChild(o),this.jsRunSequence.shift(),this.jsRunSequence.length>0&&this.runjs();else if(this.jsRunSequence[0]&&"failed"==this.jsRunSequence[0].status){var a=this,o=document.createElement("script");o.src=this.jsRunSequence[0].path,o.type="text/javascript",this.jsRunSequence[0].status="loading",o.onload=function(){a.jsRunSequence.shift(),a.jsRunSequence.length>0&&a.runjs()},document.body.appendChild(o)}},lsloader.tagLoad=function(e,t){this.jsRunSequence.push({name:t,code:"",path:e,status:"failed"}),this.runjs()},lsloader.jsfallback=function(e,t){if(!this.jsnamemap[t]){this.jsnamemap[t]=t;for(var n in this.jsRunSequence)this.jsRunSequence[n].name==t&&(this.jsRunSequence[n].code="",this.jsRunSequence[n].status="failed",this.jsRunSequence[n].path=e);this.runjs()}},lsloader.cssfallback=function(e,t,n){if(!this.cssnamemap[t]){this.cssnamemap[t]=1;var s=document.createElement("link");s.type="text/css",s.href=e,s.rel="stylesheet",s.onload=s.onerror=n;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(s,a)}},lsloader.runInlineScript=function(e,t){var n=document.getElementById(t).innerText;this.jsRunSequence.push({name:e,code:n}),this.runjs()},lsloader.loadCombo=function(e){var t="",n={};for(var s in e){var a=this.getLS(e[s].name);if(a)var o=a.split(versionString)[0],i=a.split(versionString)[1];else o="";o==e[s].path?this.jsRunSequence.push({name:e[s].name,code:i,path:e[s].path}):(this.jsRunSequence.push({name:e[s].name,code:null,path:e[s].path,status:"comboloading"}),n[e[s].name]=!0,t+=(""==t?"":";")+e[s].path)}var u=this;if(t){var r=new XMLHttpRequest;r.open("get",combo+t,!0),r.onreadystatechange=function(){if(4==r.readyState)if(r.status>=200&&r.status<300||304==r.status){if(""!=r.response)return void u.runCombo(r.response,n)}else{for(var e in u.jsRunSequence)n[u.jsRunSequence[e].name]&&(u.jsRunSequence[e].status="failed");u.runjs()}},r.send(null)}this.runjs()},lsloader.runCombo=function(e,t){(e=e.split("/*combojs*/")).shift();for(var n in this.jsRunSequence)t[this.jsRunSequence[n].name]&&e[0]&&(this.jsRunSequence[n].status="comboJS",this.jsRunSequence[n].code=e[0],this.setLS(this.jsRunSequence[n].name,this.jsRunSequence[n].path+versionString+e[0]),e.shift());this.runjs()}</script><script>function Queue(){this.dataStore=[],this.offer=function(e){this.debug&&console.log("Offered a Queued Function."),"function"==typeof e?this.dataStore.push(e):console.log("You must offer a function.")},this.poll=function(){return this.debug&&console.log("Polled a Queued Function."),this.dataStore.shift()},this.execNext=function(){var e=this.poll();void 0!==e&&(this.debug&&console.log("Run a Queued Function."),e())},this.debug=!1,this.startDebug=function(){this.debug=!0}}var queue=new Queue</script><link rel="icon shortcut" type="image/ico" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="icon" sizes="192x192" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><link rel="apple-touch-icon" href="http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="apple-mobile-web-app-title" content="Title"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="480"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="apple-mobile-web-app-title" content="Edward&#39;s Blog"> <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie-blocker.css"><script src="/js/ie-blocker.zhCN.js"></script><![endif]--><style id="material_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="style_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_css"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style id="prettify_theme"></style><script>void 0===window.lsLoadCSSMaxNums&&(window.lsLoadCSSMaxNums=0),window.lsLoadCSSMaxNums++,lsloader.load("prettify_theme","/css/prettify/github-v2.min.css?AfzKxt++K+/lhZBlSjnxwg==",function(){void 0===window.lsLoadCSSNums&&(window.lsLoadCSSNums=0),window.lsLoadCSSNums++,window.lsLoadCSSNums==window.lsLoadCSSMaxNums&&(document.documentElement.style.display="")},!1)</script><style>body,html{font-family:Roboto,"Helvetica Neue",Helvetica,"PingFang SC","Hiragino Sans GB","Microsoft YaHei","微软雅黑",Arial,sans-serif;overflow-x:hidden!important}code{font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace}a{color:#00838f}#scheme-Paradox .hot_tags-count,#scheme-Paradox .sidebar-colored .sidebar-badge,#scheme-Paradox .sidebar-colored .sidebar-header,#scheme-Paradox .sidebar_archives-count,#search-form-label:after,#search-label,.mdl-card__media{background-color:#0097a7!important}#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus,#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover{color:#0097a7!important}#ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a,#post_entry-right-info,.sidebar-colored .sidebar-nav li:hover>a,.sidebar-colored .sidebar-nav li:hover>a i,.sidebar-colored .sidebar-nav li>a:focus i,.sidebar-colored .sidebar-nav li>a:hover,.sidebar-colored .sidebar-nav li>a:hover i,.sidebar-colored .sidebar-nav>.open>a,.sidebar-colored .sidebar-nav>.open>a:focus,.sidebar-colored .sidebar-nav>.open>a:hover{color:#0097a7!important}.toTop{background:#757575!important}.material-layout .material-index>.material-nav,.material-layout .material-post>.material-nav,.material-nav a{color:#757575}#scheme-Paradox .MD-burger-layer{background-color:#757575}#scheme-Paradox #post-toc-trigger-btn{color:#757575}.post-toc a:hover{color:#00838f;text-decoration:underline}</style><style>body{background-color:#f5f5f5}#scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{background-color:#fff}</style><style>.fade{transition:all .8s linear;-webkit-transform:translate3d(0,0,0);-moz-transform:translate3d(0,0,0);-ms-transform:translate3d(0,0,0);-o-transform:translate3d(0,0,0);transform:translate3d(0,0,0);opacity:1}.fade.out{opacity:0}</style><link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet"><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"><script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==",!0)</script><meta property="og:url" content="http://pancakeawesome.ink"><meta property="og:type" content="blog"><meta property="og:title" content="集成学习之Adaboost算法原理小结 | Edward&#39;s Blog"><meta property="og:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta property="og:description" content="集成学习之Adaboost算法原理小结"><meta property="og:article:tag" content="机器学习"><meta property="article:published_time" content="Thu Apr 19 2018 11:49:57 GMT+0800"><meta property="article:modified_time" content="Thu Jun 28 2018 14:41:54 GMT+0800"><meta name="twitter:title" content="集成学习之Adaboost算法原理小结 | Edward&#39;s Blog"><meta name="twitter:description" content="集成学习之Adaboost算法原理小结"><meta name="twitter:image" content="http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="http://pancakeawesome.ink"><link rel="canonical" href="http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html"><script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html",
    "headline": "集成学习之Adaboost算法原理小结",
    "datePublished": "Thu Apr 19 2018 11:49:57 GMT+0800",
    "dateModified": "Thu Jun 28 2018 14:41:54 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Edward Guan",
        "image": {
            "@type": "ImageObject",
            "url": "/img/rip.jpeg"
        },
        "description": "你说人生艳丽我没有异议，你说人生忧郁我不言语"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Edward&#39;s Blog",
        "logo": {
            "@type":"ImageObject",
            "url": "http://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg"
        }
    },
    "keywords": ",机器学习前端,node,react,js,java,自学编程,学习分享,UESTC",
    "description": "集成学习之Adaboost算法原理小结",
}
</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0c041dca6f79c4e40fb45d1283e327e7";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body id="scheme-Paradox" class="lazy"><div class="material-layout mdl-js-layout has-drawer is-upgraded"><main class="material-layout__content" id="main"><div id="top"></div> <button class="MD-burger-icon sidebar-toggle"><span class="MD-burger-layer"></span></button> <button id="post-toc-trigger-btn" class="mdl-button mdl-js-button mdl-button--icon"> <i class="material-icons">format_list_numbered</i></button><ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh;overflow-y:scroll"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#前言"><span class="post-toc-number">1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-回顾boosting算法的基本原理"><span class="post-toc-number">2.</span> <span class="post-toc-text">1. 回顾boosting算法的基本原理</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-Adaboost算法的基本思路"><span class="post-toc-number">3.</span> <span class="post-toc-text">2. Adaboost算法的基本思路</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-AdaBoost分类问题的损失函数优化"><span class="post-toc-number">4.</span> <span class="post-toc-text">3. AdaBoost分类问题的损失函数优化</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-AdaBoost二元分类问题算法流程"><span class="post-toc-number">5.</span> <span class="post-toc-text">4. AdaBoost二元分类问题算法流程</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-Adaboost回归问题的算法流程"><span class="post-toc-number">6.</span> <span class="post-toc-text">5. Adaboost回归问题的算法流程</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-Adaboost算法的正则化"><span class="post-toc-number">7.</span> <span class="post-toc-text">6. Adaboost算法的正则化</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#后记"><span class="post-toc-number">8.</span> <span class="post-toc-text">后记</span></a></li></ol></ul><div class="material-post_container"><div class="material-post mdl-grid"><div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col"><div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50"><script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 30 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script><p class="article-headline-p"> 集成学习之Adaboost算法原理小结</p></div><div class="mdl-color-text--grey-700 mdl-card__supporting-text meta"><div id="author-avatar"> <img src="/img/rip.jpeg" width="44px" height="44px" alt="Author Avatar"></div><div> <strong>Edward Guan</strong> <span>4月 19, 2018</span></div><div class="section-spacer"></div> <button id="article-functions-qrcode-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">devices other</i> <span class="visuallyhidden">devices other</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-qrcode-button"><li class="mdl-menu__item">在其它设备中阅读本文章</li> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPYAAAD2CAAAAADAeSUUAAAC20lEQVR42u3aQW7DMAwEwPz/0+0DgjhLUmkdaXQKUNf2KEBZcvX4OXI9sLGxsbGxsbGxsW/JfsTr+fqXD3i6/tUTX11//ZTqO2NjY2OfwH7zp/+SkV9TvTLZpuQp2NjY2Oewr4tWUmB6d7suS8nGJVuDjY2Njd1rCa6LUH4lNjY2NvbaAlZ99XxglDQt2NjY2NiTodL8d5PNyluRP5qlYWNjY9+eXW0q7vD5H/JtbGxs7Fuye+t60JNsa68sjd4ZGxsbe1N20ir01qSxST6XQ2hsbGzsTdlJEJs3Azkmj3XzaOHNT7GxsbE3ZX9ukJTEvdUmZHJPbGxs7L3ZhTIwODoTDfFbR3+aqQg2Njb2RuzeccneS/eOAeVtUrNuY2NjY38tOw908xedDPd72xcdx8TGxsY+gJ23JflRyFX3Txqe5uFLbGxs7C9n52P6qEiMA+DJxmFjY2OfzM7H+tVxz3zA1IuBsbGxsc9h5/hq1NoLA6pbMBoqYWNjY2/Evr5R9YhMHsr2Cls12MDGxsbem10oAMXhfm+tLWzY2NjYJ7B7JSpvMFYVvyTiXdCBYWNjY385u/q5Gv1Wx0lJo1IIqrGxsbE3ZU+KUHXjJiUtH1QVOjBsbGzsLdh5SWg+LI6N803PYwxsbGzsE9irBveT7ejFAG8aD2xsbOwj2XlDkhSM682dNC356AobGxv7NHb1UE5vnDSJEHqxATY2NvYJ7LzYrBru5yOnXmiBjY2NfTI7H9D3xkDVkjnZYmxsbOwT2NU1f93e0L8XEmNjY2OfwJ4Hvfk29VqUpIEpH77ExsbG3o79wVFO8f69MGBBPICNjY29BTs/WJMPd/KhTx5X5E0ONjY2Nnbyr38VVm0tEmTUzGBjY2NjFx+TxwC9cVL5PtjY2NgHsKvtQbJ91eHU5Ljnm+YEGxsbe2t2L+hdewSneriz/FVhY2Njb8o+Z2FjY2NjY2NjY2PfZv0CTfpyFMGMwUYAAAAASUVORK5CYII="></ul> <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">bookmark</i> <span class="visuallyhidden">bookmark</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button"><li class="mdl-menu__item"> <a class="post_tag-link" href="/tags/机器学习/">机器学习</a></li></ul> <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"> <i class="material-icons" role="presentation">share</i> <span class="visuallyhidden">share</span></button><ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button"><a class="post_share-link" href="#"><li class="mdl-menu__item"><span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span> &nbsp;浏览量</span></li></a><a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=集成学习之Adaboost算法原理小结&url=http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html&pic=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&searchPic=false&style=simple" target="_blank"><li class="mdl-menu__item"> 分享到微博</li></a><a class="post_share-link" href="https://twitter.com/intent/tweet?text=集成学习之Adaboost算法原理小结&url=http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html&via=Edward Guan" target="_blank"><li class="mdl-menu__item"> 分享到 Twitter</li></a><a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html" target="_blank"><li class="mdl-menu__item"> 分享到 Facebook</li></a><a class="post_share-link" href="https://plus.google.com/share?url=http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html" target="_blank"><li class="mdl-menu__item"> 分享到 Google+</li></a><a class="post_share-link" href="https://www.linkedin.com/shareArticle?mini=true&url=http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html&title=集成学习之Adaboost算法原理小结" target="_blank"><li class="mdl-menu__item"> 分享到 LinkedIn</li></a><a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Edward&#39;s Blog&title=集成学习之Adaboost算法原理小结&summary=技术分享,学习笔记&pics=http://pancakeawesome.inkhttp://ornavpdfn.bkt.clouddn.com/blogCDN/icon-crown.svg&url=http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html" target="_blank"><li class="mdl-menu__item"> 分享到 QQ</li></a></ul></div><div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="http://pancakeawesome.ink/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93.html">集成学习原理小结</a>中，我们讲到了集成学习按照个体学习器之间是否存在依赖关系可以分为两类，第一个是个体学习器之间存在强依赖关系，另一类是个体学习器之间不存在强依赖关系。前者的代表算法就是是boosting系列算法。在boosting系列算法中， Adaboost是最著名的算法之一。Adaboost既可以用作分类，也可以用作回归。本文就对Adaboost算法做一个总结。</p><h2 id="1-回顾boosting算法的基本原理"><a href="#1-回顾boosting算法的基本原理" class="headerlink" title="1. 回顾boosting算法的基本原理"></a>1. 回顾boosting算法的基本原理</h2><p>在<a href="http://pancakeawesome.ink/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E5%B0%8F%E7%BB%93.html">集成学习原理小结</a> 中，我们已经讲到了boosting算法系列的基本思想，如下图：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fsgc71cgd5j30xq0tm0uv.jpg" alt=""></p><p>从图中可以看出，Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。　　</p><p>不过有几个具体的问题Boosting算法没有详细说明。</p><p>1）如何计算学习误差率e?</p><p>2) 如何得到弱学习器权重系数$\alpha$?</p><p>3）如何更新样本权重D?</p><p>4) 使用何种结合策略？</p><p>只要是boosting大家族的算法，都要解决这4个问题。那么Adaboost是怎么解决的呢？</p><h2 id="2-Adaboost算法的基本思路"><a href="#2-Adaboost算法的基本思路" class="headerlink" title="2. Adaboost算法的基本思路"></a>2. Adaboost算法的基本思路</h2><p>我们这里讲解Adaboost是如何解决上一节这4个问题的。</p><p>假设我们的训练集样本是<br>$$<br>T={(x_,y_1),(x_2,y_2), …(x_m,y_m)}<br>$$<br>训练集的在第k个弱学习器的输出权重为<br>$$<br>D(k) = (w_{k1}, w_{k2}, …w_{km}) ;\;\; w_{1i}=\frac{1}{m};\;\; i =1,2…m<br>$$</p><p>首先我们看看Adaboost的分类问题。</p><p>分类问题的误差率很好理解和计算。由于多元分类是二元分类的推广，这里假设我们是二元分类问题，输出为{-1，1}，则第k个弱分类器$G_k(x)$在训练集上的加权误差率为</p><p>$$<br>e_k = P(G_k(x_i) \neq y_i) = \sum\limits_{i=1}^{m}w_{ki}I(G_k(x_i) \neq y_i)<br>$$<br>接着我们看弱学习器权重系数,对于二元分类问题，第k个弱分类器$G_k(x)$的权重系数为</p><p>$$<br>\alpha_k = \frac{1}{2}log\frac{1-e_k}{e_k}<br>$$<br>为什么这样计算弱学习器权重系数？从上式可以看出，如果分类误差率$e_k$越大，则对应的弱分类器权重系数$\alpha_k$越小。也就是说，误差率小的弱分类器权重系数越大。具体为什么采用这个权重系数公式，我们在讲Adaboost的损失函数优化时再讲。</p><p>第三个问题，更新样本权重D。假设第k个弱分类器的样本集权重系数为$D(k) = (w_{k1}, w_{k2}, …w_{km})$，则对应的第k+1个弱分类器的样本集权重系数为<br>$$<br>w_{k+1,i} = \frac{w_{ki}}{Z_K}exp(-\alpha_ky_iG_k(x_i))<br>$$<br>这里$Z_k$是规范化因子<br>$$<br>Z_k = \sum\limits_{i=1}^{m}w_{ki}exp(-\alpha_ky_iG_k(x_i))<br>$$<br>从$w_{k+1,i}$计算公式可以看出，如果第i个样本分类错误，则$y_iG_k(x_i) &lt; 0$，导致样本的权重在第k+1个弱分类器中增大，如果分类正确，则权重在第k+1个弱分类器中减少.具体为什么采用样本权重更新公式，我们在讲Adaboost的损失函数优化时再讲。</p><p>最后一个问题是集合策略。Adaboost分类采用的是加权平均法，最终的强分类器为<br>$$<br>f(x) = sign(\sum\limits_{k=1}^{K}\alpha_kG_k(x))<br>$$<br>接着我们看看Adaboost的回归问题。由于Adaboost的回归问题有很多变种，这里我们以Adaboost R2算法为准。</p><p>我们先看看回归问题的误差率的问题，对于第k个弱学习器，计算他在训练集上的最大误差<br>$$<br>E_k= max|y_i - G_k(x_i)|\;i=1,2…m<br>$$<br>然后计算每个样本的相对误差<br>$$<br>e_{ki}= \frac{|y_i - G_k(x_i)|}{E_k}<br>$$<br>这里是误差损失为线性时的情况，如果我们用平方误差，则$e_{ki}= \frac{(y_i - G_k(x_i))^2}{E_k^2}$,如果我们用的是指数误差，则$e_{ki}= 1 - exp（\frac{-y_i + G_k(x_i))}{E_k}）$</p><p>最终得到第k个弱学习器的 误差率<br>$$<br>e_k = \sum\limits_{i=1}^{m}w_{ki}e_{ki}<br>$$<br>我们再来看看如何得到弱学习器权重系数$\alpha$。这里有：<br>$$<br>\alpha_k =\frac{e_k}{1-e_k}<br>$$<br>对于更新更新样本权重D，第k+1个弱学习器的样本集权重系数为<br>$$<br>w_{k+1,i} = \frac{w_{ki}}{Z_k}\alpha_k^{1-e_{ki}}<br>$$<br>这里$Z_k$是规范化因子<br>$$<br>Z_k = \sum\limits_{i=1}^{m}w_{ki}\alpha_k^{1-e_{ki}}<br>$$<br>最后是结合策略，和分类问题稍有不同，采用的是对加权的弱学习器取中位数的方法，最终的强回归器为<br>$$<br>f(x) = \sum\limits_{k=1}^{K}(ln\frac{1}{\alpha_k})g(x)<br>$$<br>　　其中，$g(x)$是所有$\alpha_kG_k(x), k=1,2,….K$的中位数。　</p><h2 id="3-AdaBoost分类问题的损失函数优化"><a href="#3-AdaBoost分类问题的损失函数优化" class="headerlink" title="3. AdaBoost分类问题的损失函数优化"></a>3. AdaBoost分类问题的损失函数优化</h2><p>刚才上一节我们讲到了分类Adaboost的弱学习器权重系数公式和样本权重更新公式。但是没有解释选择这个公式的原因，让人觉得是魔法公式一样。其实它可以从Adaboost的损失函数推导出来。</p><p>从另一个角度讲，　Adaboost是模型为加法模型，学习算法为前向分步学习算法，损失函数为指数函数的分类问题。</p><p>模型为加法模型好理解，我们的最终的强分类器是若干个弱分类器加权平均而得到的。</p><p>前向分步学习算法也好理解，我们的算法是通过一轮轮的弱学习器学习，利用前一个弱学习器的结果来更新后一个弱学习器的训练集权重。也就是说，第k-1轮的强学习器为<br>$$<br>f_{k-1}(x) = \sum\limits_{i=1}^{k-1}\alpha_iG_{i}(x)<br>$$<br>而第k轮的强学习器为<br>$$<br>f_{k}(x) = \sum\limits_{i=1}^{k}\alpha_iG_{i}(x)<br>$$<br>上两式一比较可以得到<br>$$<br>f_{k}(x) = f_{k-1}(x) + \alpha_kG_k(x)<br>$$<br>可见强学习器的确是通过前向分步学习算法一步步而得到的。</p><p>Adaboost损失函数为指数函数，即定义损失函数为<br>$$<br>\underbrace{arg\;min\;}_{\alpha, G} \sum\limits_{i=1}^{m}exp(-y_if_{k}(x))<br>$$<br>利用前向分步学习算法的关系可以得到损失函数为<br>$$<br>(\alpha_k, G_k(x)) = \underbrace{arg\;min\;}_{\alpha, G}\sum\limits_{i=1}^{m}exp[(-y_i) (f_{k-1}(x) + \alpha G(x))]<br>$$<br>令$w_{ki}^{’} = exp(-y_if_{k-1}(x))$, 它的值不依赖于$\alpha$, G,因此与最小化无关，仅仅依赖于$f_{k-1}(x)$,随着每一轮迭代而改变。</p><p>将这个式子带入损失函数,损失函数转化为<br>$$<br>(\alpha_k, G_k(x)) = \underbrace{arg\;min\;}_{\alpha, G}\sum\limits_{i=1}^{m}w_{ki}^{’}exp[-y_i\alpha G(x)]<br>$$<br>首先，我们求$G_k(x)$.，可以得到<br>$$<br>G_k(x) = \underbrace{arg\;min\;}_{G}\sum\limits_{i=1}^{m}w_{ki}^{’}I(y_i \neq G(x_i))<br>$$<br>将$G_k(x)$带入损失函数，并对$\alpha$求导，使其等于0，则就得到了<br>$$<br>\alpha_k = \frac{1}{2}log\frac{1-e_k}{e_k}<br>$$<br>其中，$e_k$即为我们前面的分类误差率。<br>$$<br>e_k = \frac{\sum\limits_{i=1}^{m}w_{ki}^{’}I(y_i \neq G(x_i))}{\sum\limits_{i=1}^{m}w_{ki}^{’}} = \sum\limits_{i=1}^{m}w_{ki}I(y_i \neq G(x_i))<br>$$<br>最后看样本权重的更新。利用f$f_{k}(x) = f_{k-1}(x) + \alpha_kG_k(x)$ 和$w_{ki}^{’} = exp(-y_if_{k-1}(x))$，即可得：<br>$$<br>w_{k+1,i}^{’} = w_{ki}^{’}exp[-y_i\alpha_kG_k(x)]<br>$$<br>这样就得到了我们第二节的样本权重更新公式。</p><h2 id="4-AdaBoost二元分类问题算法流程"><a href="#4-AdaBoost二元分类问题算法流程" class="headerlink" title="4. AdaBoost二元分类问题算法流程"></a>4. AdaBoost二元分类问题算法流程</h2><p>这里我们对AdaBoost二元分类问题算法流程做一个总结。</p><p>输入为样本集$T={(x_,y_1),(x_2,y_2), …(x_m,y_m)}$，输出为{-1, +1}，弱分类器算法, 弱分类器迭代次数K。</p><p>输出为最终的强分类器$f(x)$</p><p>1) 初始化样本集权重为<br>$$<br>D(1) = (w_{11}, w_{12}, …w_{1m}) ;\;\; w_{1i}=\frac{1}{m};\;\; i =1,2…m<br>$$<br>2) 对于k=1,2，…K:</p><p>　　a) 使用具有权重$D_k$的样本集来训练数据，得到弱分类器$G_k(x)$</p><p>　　b)计算$G_k(x)$的分类误差率<br>$$<br>e_k = P(G_k(x_i) \neq y_i) = \sum\limits_{i=1}^{m}w_{ki}I(G_k(x_i) \neq y_i)<br>$$<br>　　c) 计算弱分类器的系数<br>$$<br>\alpha_k = \frac{1}{2}log\frac{1-e_k}{e_k}<br>$$<br>　　d) 更新样本集的权重分布<br>$$<br>w_{k+1,i} = \frac{w_{ki}}{Z_K}exp(-\alpha_ky_iG_k(x_i)) \;\; i =1,2,…m<br>$$<br>这里$Z_k$是规范化因子<br>$$<br>Z_k = \sum\limits_{i=1}^{m}w_{ki}exp(-\alpha_ky_iG_k(x_i))<br>$$<br>3) 构建最终分类器为：<br>$$<br>f(x) = sign(\sum\limits_{k=1}^{K}\alpha_kG_k(x))<br>$$<br>对于Adaboost多元分类算法，其实原理和二元分类类似，最主要区别在弱分类器的系数上。比如Adaboost SAMME算法，它的弱分类器的系数<br>$$<br>\alpha_k = \frac{1}{2}log\frac{1-e_k}{e_k} + log(R-1)<br>$$<br>其中R为类别数。从上式可以看出，如果是二元分类，R=2，则上式和我们的二元分类算法中的弱分类器的系数一致。</p><h2 id="5-Adaboost回归问题的算法流程"><a href="#5-Adaboost回归问题的算法流程" class="headerlink" title="5. Adaboost回归问题的算法流程"></a>5. Adaboost回归问题的算法流程</h2><p>这里我们对AdaBoost回归问题算法流程做一个总结。AdaBoost回归算法变种很多，下面的算法为Adaboost R2回归算法过程。</p><p>输入为样本集$T={(x_,y_1),(x_2,y_2), …(x_m,y_m)}$，弱学习器算法, 弱学习器迭代次数K。</p><p>输出为最终的强学习器$f(x)$</p><p>1) 初始化样本集权重为<br>$$<br>D(1) = (w_{11}, w_{12}, …w_{1m}) ;\;\; w_{1i}=\frac{1}{m};\;\; i =1,2…m<br>$$<br>2) 对于k=1,2，…K:</p><p>　　a) 使用具有权重$D_k$的样本集来训练数据，得到弱学习器$G_k(x)$</p><p>　　b) 计算训练集上的最大误差<br>$$<br>E_k= max|y_i - G_k(x_i)|\;i=1,2…m<br>$$<br>　　c) 计算每个样本的相对误差:</p><p>如果是线性误差，则$e_{ki}= \frac{|y_i - G_k(x_i)|}{E_k}$；</p><p>如果是平方误差，则$e_{ki}= \frac{(y_i - G_k(x_i))^2}{E_k^2}$</p><p>如果是指数误差，则$e_{ki}= 1 - exp（\frac{-|y_i -G_k(x_i)|}{E_k}）$</p><p>　　d) 计算回归误差率<br>$$<br>e_k = \sum\limits_{i=1}^{m}w_{ki}e_{ki}<br>$$<br>　　e) 计算弱学习器的系数<br>$$<br>\alpha_k =\frac{e_k}{1-e_k}<br>$$<br>　　f) 更新样本集的权重分布为<br>$$<br>w_{k+1,i} = \frac{w_{ki}}{Z_k}\alpha_k^{1-e_{ki}}<br>$$<br>这里$Z_k$是规范化因子<br>$$<br>Z_k = \sum\limits_{i=1}^{m}w_{ki}\alpha_k^{1-e_{ki}}<br>$$<br>3) 构建最终强学习器为：<br>$$<br>f(x) = \sum\limits_{k=1}^{K}(ln\frac{1}{\alpha_k})g(x)<br>$$</p><p>　　其中，$g(x)$是所有$G_k(x), k=1,2,….K$的中位数。</p><h2 id="6-Adaboost算法的正则化"><a href="#6-Adaboost算法的正则化" class="headerlink" title="6. Adaboost算法的正则化"></a>6. Adaboost算法的正则化</h2><p>为了防止Adaboost过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长(learning rate)。定义为$nu$,对于前面的弱学习器的迭代<br>$$<br>f_{k}(x) = f_{k-1}(x) + \alpha_kG_k(x)<br>$$<br>如果我们加上了正则化项，则有<br>$$<br>f_{k}(x) = f_{k-1}(x) + \nu\alpha_kG_k(x)<br>$$<br>$\nu$的取值范围为$0 &lt; \nu \leq 1 $。对于同样的训练集学习效果，较小的$\nu$意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>到这里Adaboost就写完了，前面有一个没有提到，就是弱学习器的类型。理论上任何学习器都可以用于Adaboost.但一般来说，使用最广泛的Adaboost弱学习器是决策树和神经网络。对于决策树，Adaboost分类用了CART分类树，而Adaboost回归用了CART回归树。</p><p>这里对Adaboost算法的优缺点做一个总结。</p><p>Adaboost的主要优点有：</p><p>1）Adaboost作为分类器时，分类精度很高</p><p>2）在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。</p><p>3）作为简单的二元分类器时，构造简单，结果可理解。</p><p>4）不容易发生过拟合</p><p>Adaboost的主要缺点有：</p><p>1）对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。</p><blockquote style="margin:2em 0 0;padding:.5em 1em;border-left:3px solid #f44336;background-color:#f5f5f5;list-style:none"><p> <strong>This blog is under a <a href="https://pancakeawesome.ink/" target="_blank">CC BY-NC-SA 3.0 Unported License</a></strong><br> <strong>本文链接：</strong><a href="http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html">http://pancakeawesome.ink/集成学习之Adaboost算法原理小结.html</a></p></blockquote></div><div id="changyan-comment"><div id="SOHUCS" sid="集成学习之Adaboost算法原理小结.html"></div><script type="text/javascript">!function(){var t="da223e602e0abf03eded8d4c19e7d862";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=cytdf2o7Q&conf='+t+'"><\/script>');else{!function(t,e){var n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,a=document.createElement("script");a.setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:"cytdf2o7Q",conf:t})})}}()</script></div><style>#changyan-comment{background-color:#eee;padding:2pc}</style></div><nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col"> <a href="/梯度提升树-GBDT-原理小结.html" id="post_nav-newer" class="prev-content"><button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_back</i></button> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 新篇</a><div class="section-spacer"></div> <a href="/LSTM模型小结.html" id="post_nav-older" class="next-content">旧篇 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation"> <i class="material-icons">arrow_forward</i></button></a></nav></div></div><div class="sidebar-overlay"></div><aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation"><div id="sidebar-main"><div class="sidebar-header header-cover" style="background-image:url(/img/thumbnail/sidebar_header.jpg)"><div class="top-bar"></div> <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display:initial" data-upgraded=",MaterialButton,MaterialRipple"> <i class="material-icons">clear_all</i><span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></button><div class="sidebar-image"> <img src="/img/rip.jpeg" alt="Edward Guan's avatar"></div> <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">guanchao930908@163.com<b class="caret"></b></a></div><ul class="nav sidebar-nav"><li class="dropdown"><ul id="settings-dropdown" class="dropdown-menu"><li> <a href="mailto:guanchao930908@163.com" target="_blank" title="Email Me"><i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i> Email Me</a></li></ul></li><li id="sidebar-first-li"> <a href="/"><i class="material-icons sidebar-material-icons">home</i> 主页</a></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">timeline</i> 归档<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/archives/2018/07/">七月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">14</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/02/">二月 2018<span class="sidebar_archives-count">19</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">13</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/10/">十月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">10</span></a></li></ul></li><li class="dropdown"> <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown"><i class="material-icons sidebar-material-icons">chrome_reader_mode</i> 分类<b class="caret"></b></a><ul class="dropdown-menu"><li> <a class="sidebar_archives-link" href="/categories/OCR/">OCR<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/blog/">blog<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/categories/javascript/">javascript<span class="sidebar_archives-count">12</span></a></li><li><a class="sidebar_archives-link" href="/categories/nodejs/">nodejs<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/react/">react<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端工具/">前端工具<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/categories/前端技术/">前端技术<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据分析/">数据分析<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据可视化/">数据可视化<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/机器学习/">机器学习<span class="sidebar_archives-count">25</span></a></li><li><a class="sidebar_archives-link" href="/categories/深度学习/">深度学习<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/categories/目标检测/">目标检测<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/算法思想/">算法思想<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/计算机网络/">计算机网络<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/论文笔记/">论文笔记<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/软件开发/">软件开发<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/面试/">面试<span class="sidebar_archives-count">1</span></a></li></ul></li><li> <a href="/tags" title="标签云"><i class="material-icons sidebar-material-icons">cloud_circle</i> 标签云</a></li><li class="divider"></li><li> <a href="/timeline" title="Timeline"><i class="material-icons sidebar-material-icons">send</i> Timeline</a></li><li> <a href="/gallery" title="Gallery"><i class="material-icons sidebar-material-icons">photo_library</i> Gallery</a></li><li> <a href="/aboutMe" title="About Me"><i class="material-icons sidebar-material-icons">person_pin</i> About Me</a></li><li class="divider"></li><li> <a href="/archives">文章总数 <span class="sidebar-badge">101</span></a></li></ul></div></aside><div id="back-to-top" class="toTop-wrap"> <a href="#top" class="toTop"><i class="material-icons footer_top-i">expand_less</i></a></div><footer class="mdl-mini-footer" id="bottom"><div class="mdl-mini-footer--left-section sns-list"> <a href="https://twitter.com/591153977" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-twitter"> <span class="visuallyhidden">Twitter</span></button></a> <a href="https://www.facebook.com/profile.php?id=100011433530812" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-facebook"> <span class="visuallyhidden">Facebook</span></button></a> <a href="https://www.instagram.com/edward930908/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-instagram"> <span class="visuallyhidden">Instagram</span></button></a> <a href="https://github.com/PancakeAwesome" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-github"> <span class="visuallyhidden">Github</span></button></a> <a href="https://www.linkedin.com/in/%E8%B6%85-%E7%AE%A1-89495a145/" target="_blank"><button class="mdl-mini-footer--social-btn social-btn footer-sns-linkedin"> <span class="visuallyhidden">LinkedIn</span></button></a></div><div id="copyright"> Copyright&nbsp;©<script type="text/javascript">var fd=new Date;document.write("&nbsp;"+fd.getFullYear()+"&nbsp;")</script>Edward's Blog<br><p>Hosted by <a href="https://pages.coding.me" style="font-weight:700">Coding Pages</a></p></div><div class="mdl-mini-footer--right-section"><div><div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div><div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div></div></div></footer><script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==",!0)</script><script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==",!0)</script><script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==",!0)</script><script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><script id="cy_cmt_num" src="https://changyan.sohu.com/upload/plugins/plugins.list.count.js?clientId=cytdf2o7Q"></script><script>var agent=navigator.userAgent.toLowerCase();agent.indexOf("ucbrowser")>0&&(document.write('<link rel="stylesheet" href="/css/uc.css">'),alert("由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。"))</script><script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==",!0)</script><script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script><script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script><script>!function(){for(var e=document.querySelectorAll('script[type="text/ls-javascript"]'),r=0;r<e.length;++r){var o=e[r];lsloader.runInlineScript(o.id,o.id)}}(),console.log("\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;","color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;")</script></main></div><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>